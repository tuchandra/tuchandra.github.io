<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <title>
    Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML - Tushar Chandra
    </title>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" /><meta name="description" content="Speaker: Patrick Hall (H2O.ai).
" />
  <meta name="generator" content="Hugo 0.70.0" />
  <title>Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML - Tushar Chandra</title>

  
  
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">

  <meta property="og:title" content="Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML" />
<meta property="og:description" content="Speaker: Patrick Hall (H2O.ai)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/spark/interpretable_ai.html" />
<meta property="article:published_time" content="2019-04-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-04-24T00:00:00+00:00" />
<meta itemprop="name" content="Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML">
<meta itemprop="description" content="Speaker: Patrick Hall (H2O.ai).">
<meta itemprop="datePublished" content="2019-04-24T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-04-24T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1563">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML"/>
<meta name="twitter:description" content="Speaker: Patrick Hall (H2O.ai)."/>
</head>
</head>



<body class="h-full flex flex-col justify-between" itemscope itemtype="http://schema.org/WebPage"><header class="w-screen bg-green-500" itemscope itemtype="http://schema.org/WPHeader">
  <div class="flex max-w-8xl container mx-auto">
    <div class="hidden sm:inline flex items-center">
      <a href="/">
        <img class="rounded-full m-1 md:m-4" src="/headshot.jpg" width="100" height="100">
      </a>
    </div>
    <div class="w-full px-4 flex flex-col lg:flex-row justify-start md:pt-4 lg:items-center my-4">
      <div class="lg:flex-grow">
        <a href="/">
          <span class="text-lg sm:text-2xl md:text-3xl font-semibold">Tushar Chandra</span>
          <span class="hidden pl-4 lg:inline"><br></span>
          <span class="text-sm md:text-xl font-thin pl-4 md:pl-8 lg:pl-0 lg:text-xl">Data Scientist / Chicago, IL
          </span>
        </a>
      </div>
      <nav class="" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="flex lg:justify-between">
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/about">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-mug-hot"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">About</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/resume">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-file"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Resume</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/reading">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-book-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Reading</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/categories.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-folder-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Categories</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/posts.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-archive"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Archives</span>
              </a>
            </p>
          </li>

        </ul>

      </nav>
    </div>

  </div>
</header>
  <div class="container mx-auto max-w-8xl px-4 flex flex-row flex-grow">
    <div class="w-full md:w-3/4">
      
<main class="main" role="main"><div class="content container mx-auto max-w-6xl">
  <article id="-" class="" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="pt-4">
      <span class="font-semibold text-3xl"><h1 itemprop="name">
  <a class="" href="/spark/interpretable_ai.html">Beyond Reason Codes: A Blueprint for Human-Centered, Low-Risk ML</a>
</h1>
      </span>
      <div class="pb-4"><i class="fas fa-calendar-check text-gray-500 pr-1"></i>
<time datetime="2019-04-24 00:00:00 &#43;0000 UTC" class="text-sm text-gray-600"
  itemprop="datePublished">2019-04-24</time>
<span class="text-sm text-gray-600" itemprop="wordCount">
	<i class="fas fa-pencil-alt text-gray-500 pl-4 pr-2"></i>1563 words
</span><i class="fas fa-folder-open text-gray-500 pl-4 pr-1"></i>
<a class="text-sm text-gray-600" href=" /categories/spark.html"> spark, </a>
      </div>
    </div>
    <div class="rich-text" itemprop="articleBody">
      <p>Speaker: Patrick Hall (H2O.ai).</p>
<h2 id="the-ml-lifecycle"><a class="not-rich" href="#the-ml-lifecycle"><i class="fas fa-link"></i></a> The ML Lifecycle</h2>
<p>Opened with a slide about the same data science lifecycle that we&rsquo;ve seen over and over. &ldquo;Here&rsquo;s the workflow that you wouldn&rsquo;t shoot yourself in the foot with … and also take into consideration a lot of human aspects of what we do.&rdquo; He said that it&rsquo;s important for fairness concerns, ethical concerns, and much more.</p>
<p>He is very worried that if we (data scientists, engineers, etc.) don&rsquo;t take it upon ourselves to regulate practices, then a government will come in and be like &ldquo;you can&rsquo;t do this, you can&rsquo;t do that, you can only do this&rdquo; in some crazy draconian way. Which … yeah that&rsquo;s true.</p>
<p>Don&rsquo;t let perfect be the enemy of good here: it would be difficult for everyone to do everything on this slide, but you gotta start somewhere.</p>
<p>This talk <em>starts</em> with the assumption that you have all your data in one place, that it&rsquo;s all clean, etc.; other talks at this conference can go into how you get there.</p>
<h3 id="eda-and-data-visualization"><a class="not-rich" href="#eda-and-data-visualization"><i class="fas fa-link"></i></a> EDA and Data Visualization</h3>
<p>This is basically business as usual. References:</p>
<ul>
<li>H2O-3 aggregator</li>
<li>The Grammar of Graphics</li>
</ul>
<h3 id="establish-benchmarks"><a class="not-rich" href="#establish-benchmarks"><i class="fas fa-link"></i></a> Establish Benchmarks</h3>
<p>You have to start with some kinds of benchmarks, before any feature engineering gets done - run a linear regression or single decision tree. Don&rsquo;t <em>only</em> think about accuracy, think about disparate impact or security or privacy or other things … accuracy is important, but not as important as a lot of people think it is (we measure accuracy on static test datasets and then apply it in the real world).</p>
<p>Establish benchmark —&gt; then you can gauge improvements in fairness, interpretability, privacy, or security.</p>
<h3 id="feature-engineering"><a class="not-rich" href="#feature-engineering"><i class="fas fa-link"></i></a> Feature engineering</h3>
<p>References:</p>
<ul>
<li>Pandas Profiler</li>
<li>FeatureTools</li>
<li>Deep Feature Synthesis (<a href="http://www.jmaxkanter.com/static/papers/DSAA_DSM_2015.pdf">paper</a>)</li>
</ul>
<p>Features will have to be explained and justified. Don&rsquo;t introduce undue complexity in feature engineering; if you&rsquo;re using autoencoder features you might have to explain them one day.</p>
<h3 id="preprocessing-for-fairness-privacy-or-security"><a class="not-rich" href="#preprocessing-for-fairness-privacy-or-security"><i class="fas fa-link"></i></a> Preprocessing for fairness, privacy, or security</h3>
<p>There are lots of things you can do to make data more &ldquo;private&rdquo; or &ldquo;fair.&rdquo; Preprocess data to remove disparate impact (&ldquo;when your predictions are more than 20% different for one group vs. another group&rdquo;, which is a legal definition). There are tools to preprocess causes of disparate impact out of your data, if you want to use them.</p>
<p>You can also preprocess to remove PII, which is super <em>super</em> important.</p>
<h3 id="modeling-constrained-fair-interpretable-private-or-simple-models"><a class="not-rich" href="#modeling-constrained-fair-interpretable-private-or-simple-models"><i class="fas fa-link"></i></a> Modeling: constrained, fair, interpretable, private, or simple models</h3>
<p>We all want to do deep learning … but when we do the most complex ones, we get ourselves into trouble w.r.t. explanation, or proving a lack of disparate impact, or proving that your model wasn&rsquo;t hacked (e.g., adversarially).</p>
<p>If your model is so complex that you can&rsquo;t explain it, how do you know no one has changed it?</p>
<ul>
<li>Explainable Neural Networks based on Additive Index Models (XNN)</li>
<li>Learning Fair Representations (LFR)</li>
<li>LIME, LIME-SUP (the SUP is supervised partitioning)</li>
<li>Private Aggregation of Teacher Ensembles (PATE, secure and private)</li>
<li>Scalable Bayesian Rule Lists (SBRL, rules printed in orders of importance)</li>
</ul>
<p>Favorite example: monotonic gradient boosting trees. This lets you explain things by being able to say &ldquo;if this input goes up, our probability <em>only</em> goes up.&rdquo; <strong>Monotonicity</strong> is a super useful and popular part of interpretability. You&rsquo;re not just stuck with linear models and random forests!</p>
<p>###Traditional model assessment and diagnostics</p>
<p>The same metrics as usual matter; AUC on train, test, validation, accuracy, whatever. This isn&rsquo;t that different.</p>
<h3 id="post-hoc-explanations"><a class="not-rich" href="#post-hoc-explanations"><i class="fas fa-link"></i></a> Post-hoc explanations</h3>
<p><strong>OSS resources</strong>: LIME or SHAP. Papers include:</p>
<ul>
<li><a href="https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf">Why should I trust you? Explaining the predictions of any classifier</a> — this is the LIME paper</li>
<li><a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">A unified approach to interpreting model predictions</a> — this is the SHAP paper</li>
<li><a href="https://arxiv.org/abs/1811.10154">Please stop explaining black box models for high stakes decisions</a> - criticism</li>
</ul>
<p>Also talked about <strong>Shapley values</strong>, which came from the 1950s but didn&rsquo;t make it into ML until 2017. It is &ldquo;the player&rsquo;s contribution to a cooperative game,&rdquo; but instead we think about features in a model. They disaggregate the contribution of each variable for every prediction, much like the value of every person to a game. Lloyd Shapley won the Nobel Prize for this in 2012.</p>
<p>The 2017 SHAP paper managed to take Shapley values from being exponential time to log polynomial time, which is huge! They are consistent (if you change your model or data a little bit, this is pretty stable). It tells you the feature contribution of every single row in your dataset very accurately, which is incredible!</p>
<h3 id="model-debugging"><a class="not-rich" href="#model-debugging"><i class="fas fa-link"></i></a> Model debugging</h3>
<p>This is related to model diagnostics, but the first academic workshop about this will probably happen in two weeks at ICLR. It can mostly be defined as testing your model to find problems with accuracy or security that you can fix. OSS libraries include <strong>cleverhans</strong>, pdpbox, and <strong>what-if-tool.</strong> They&rsquo;re all based on sensitivity analysis (which you should probably always be doing in ML).</p>
<p>Cleverhans looks for the minimal change you can make to change the output of the model; this shows how models can be hackable. If you have a prediction API out there, then people know how to steal your model … and they can do sensitivity analysis and understand how they can get the output to flip the predictions.</p>
<p>pdpbox does partial dependence, telling you how much data you have in certain regions of feature space. If your data is sparse, pdpbox can identify that and tell you about it.</p>
<p>what-if-tool is from Google and answers the question &ldquo;what happens if you do this&rdquo; like switch someone&rsquo;s gender. If you change your data and see what happens, that&rsquo;s a very impactful testing tool.</p>
<p>Papers include:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1811.01134.pdf">A Marauder&rsquo;s Map of Security and Privacy in Machine Learning: an overview of current and future research directions for making machine learning secure and private</a></li>
<li><a href="http://saleemaamershi.com/papers/amershi.CHI2015.ModelTracker.pdf">Modeltracker: Redesigning Performance Analysis Tools for ML</a></li>
<li><a href="https://people.eecs.berkeley.edu/~adj/publications/paper-files/SecML-MLJ2010.pdf">The Security of Machine Learning</a></li>
</ul>
<p>This kind of testing is super <em>super</em> important to do, because you have to understand what happens when you see something outside of your training data.</p>
<h3 id="post-hoc-disparate-impact-analysis-and-remediation"><a class="not-rich" href="#post-hoc-disparate-impact-analysis-and-remediation"><i class="fas fa-link"></i></a> Post-hoc disparate impact analysis and remediation</h3>
<p>Again, disparate impact is legally defined, &ldquo;when your predictions are more than 20% different for one group vs. another group.&rdquo; If you&rsquo;re doing ML that involves people, this is essential to do.</p>
<p>There&rsquo;s a concept called the &ldquo;multiplicity of good models,&rdquo; where for any good dataset there are usually lots of good models. You can probably find a model without disparate impact that is just as good as one that does have it.</p>
<p>OSS includes <strong>aequitas</strong> and <strong>themis</strong>.</p>
<p>Papers include:</p>
<ul>
<li><a href="https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf">Equality of Opportunity in Supervised Learning</a></li>
<li><a href="http://sorelle.friedler.net/papers/kdd_disparate_impact.pdf">Certifying and Removing Disparate Impact</a></li>
</ul>
<h3 id="human-review-and-documentation"><a class="not-rich" href="#human-review-and-documentation"><i class="fas fa-link"></i></a> Human Review and Documentation</h3>
<p>This is the most important part even when people don&rsquo;t care about the other stuff - this is how you preserve knowledge so you have reports of what people did (&ldquo;when all your hotshot data scientists leave for other jobs&rdquo;). Google just wrote a paper (<a href="https://arxiv.org/pdf/1810.03993.pdf">Model Cards for Model Reporting</a>) about this, but it&rsquo;s something banks have been doing for decades.</p>
<p>For every model they train at H2O.ai, they generate a very basic report - what was the data, what was the model, what features were used, who trained it, when was it trained, etc. - and that saves a ton of time and is a sound business practice.</p>
<h3 id="deployment"><a class="not-rich" href="#deployment"><i class="fas fa-link"></i></a> Deployment</h3>
<p>A lot of data scientist struggle with the problem of &ldquo;I&rsquo;ve got all my beautiful and perfect Python code on my laptop, and now it has to run on this server in C#?&rdquo; Deployment is the most important part of the process — until you&rsquo;ve deployed you&rsquo;re just a cost center. Undue complexity will harm deployment, and that will cost you accuracy (because the time between train and prod will increase).</p>
<h3 id="human-appeal"><a class="not-rich" href="#human-appeal"><i class="fas fa-link"></i></a> Human Appeal</h3>
<p>If you are doing machine learning that involves making decisions on people, they should be allowed to appeal those decisions; full stop. We all know that there can be all kinds of data quality problems, the data can be completely wrong, or the model may do a bad job.</p>
<p>He gave an example of apps that may have rankings for babysitters, and if you are a babysitter who gets a bad ranking based on some model, then suddenly you might lose your part time job … again, all banks follow this, if you&rsquo;re denied a credit card they have to tell you how you can improve. But that&rsquo;s not the case (yet) in ML.</p>
<h3 id="iterate"><a class="not-rich" href="#iterate"><i class="fas fa-link"></i></a> Iterate</h3>
<p>Think about things besides accuracy - the test data accuracy is probably not as meaningful as we hope it is. Think about privacy, security, interpretability, fairness. KPIs should not just be restricted to accuracy (or related metrics).</p>
<h2 id="open-questions"><a class="not-rich" href="#open-questions"><i class="fas fa-link"></i></a> Open Questions</h2>
<p>How much automation of this is appropriate? How much is possible?</p>
<p>How do you automate learning by iteration, e.g., via reinforcement learning? We&rsquo;re trying to keep people in the process, but one of the reasons we take people <em>out</em> of the process is because they have these inherent biases.</p>
<p>How do you implement human appeals, from an HCI perspective?</p>
<p>Links:</p>
<ul>
<li><a href="https://github.com/jphall663/awesome-machine-learning-interpretability">Awesome Machine Learning Interpretability</a></li>
<li><a href="https://github.com/jphall663/interpretable_machine_learning_with_python">Interpretable Machine Learning with Python</a></li>
</ul>
<p>Question from the audience was &ldquo;what would you do?&rdquo; Monotonic xgboost with partial dependence and ICE plots, notebook <a href="https://github.com/jphall663/interpretable_machine_learning_with_python/blob/master/xgboost_pdp_ice.ipynb">here</a>.</p>
<p>Another question: you can kind of explain any model, but also don&rsquo;t use autoencoder features, is that a contradiction? Answer is that you <em>can</em> explain them, but it&rsquo;s way harder than other features. Whether that matters or not depends on your use case.</p>
<p>This talk was awesome.</p>

      <p><i class="fas fa-square font-green-800"></i></p>
    </div>
    <div class="font-semibold text-green-800 pt-4">
      <a href="/"><i class="fas fa-arrow-left"></i> Return home</a>
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/spark/transfer_learning.html" title="High Performance Transfer Learning for Classifying Intent of Sales Engagement Emails: An Experimental Study"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;</span></a>
            </li>
            <li class="next">
                <a href="/spark/query_plans.html"
                    title="Understanding Query Plans and Spark UIs"><span>&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>

</main>
    </div>
    <div class="hidden w-0 md:block md:w-1/4 md:pt-8 md:pl-12"><aside class="" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="pb-8">
    <h3 class="font-semibold text-xl">Categories</h3>
    <ul class="">
        <li class="">+ <a href="/categories/books.html" class="font-bold text-green-900">books
            </a><span class="">25</span>
        </li>
        <li class="">+ <a href="/categories/general.html" class="font-bold text-green-900">general
            </a><span class="">41</span>
        </li>
        <li class="">+ <a href="/categories/papers.html" class="font-bold text-green-900">papers
            </a><span class="">84</span>
        </li>
        <li class="">+ <a href="/categories/projects.html" class="font-bold text-green-900">projects
            </a><span class="">7</span>
        </li>
        <li class="">+ <a href="/categories/self.html" class="font-bold text-green-900">self
            </a><span class="">4</span>
        </li>
        <li class="">+ <a href="/categories/spark.html" class="font-bold text-green-900">spark
            </a><span class="">34</span>
        </li>
        <li class="">+ <a href="/categories/what-i-read.html" class="font-bold text-green-900">what-i-read
            </a><span class="">51</span>
        </li>
    </ul>
</div>
<div class="pb-4">
    <h3 class="font-semibold text-xl">Recent Posts</h3>
    <ul class="recent-post-list list-unstyled no-thumbnail">
        <li class="pb-4">
            <p>
                <a href="/papers/weekly_suicide_prediction_choudhury.html" class="font-bold text-green-900">[Paper] Development of a Machine Learning Model Using Multiple, Heterogeneous Data Sources to Estimate Weekly US Suicide Fatalities</a>
                <time datetime="2020-12-24 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-12-24
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/generalists_specialists_anderson.html" class="font-bold text-green-900">[Paper] Generalists and Specialists: Using Community Embeddings to Quantify Activity Diversity in Online Platforms</a>
                <time datetime="2020-12-22 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-12-22
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/psychosocial_effects_covid_saha.html" class="font-bold text-green-900">[Paper] Psychosocial Effects of the COVID-19 Pandemic: Large-scale Quasi-Experimental Study on Social Media</a>
                <time datetime="2020-12-15 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-12-15
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/experiment_operationalizing_ai_ethics.html" class="font-bold text-green-900">[Paper] Biased Programmers? Or Biased Data? A Field Experiment in Operationalizing AI Ethics</a>
                <time datetime="2020-12-14 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-12-14
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/books/little_book_hygge.html" class="font-bold text-green-900">My review of The Little Book of Hygge</a>
                <time datetime="2020-12-12 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-12-12
                </time>
            </p>

        </li>
    </ul>
</div><div class="pb-12">
    <h3 class="font-semibold text-xl">Tags</h3>
    <ul class="">
        <li class="">+ <a href="/tags/#republic.html" class="font-bold text-green-900">#republic
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/chi2019.html" class="font-bold text-green-900">chi2019
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/chi2020.html" class="font-bold text-green-900">chi2020
            </a><span class="">20</span>
        </li>
        <li class="">+ <a href="/tags/cscw2020.html" class="font-bold text-green-900">cscw2020
            </a><span class="">8</span>
        </li>
        <li class="">+ <a href="/tags/fat2020.html" class="font-bold text-green-900">fat2020
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/iclr.html" class="font-bold text-green-900">iclr
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/icwsm2020.html" class="font-bold text-green-900">icwsm2020
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/indistractable.html" class="font-bold text-green-900">indistractable
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/neurips.html" class="font-bold text-green-900">neurips
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/password-tool.html" class="font-bold text-green-900">password-tool
            </a><span class="">6</span>
        </li>
        <li class="">+ <a href="/tags/reading-club.html" class="font-bold text-green-900">reading-club
            </a><span class="">17</span>
        </li>
        <li class="">+ <a href="/tags/recsys.html" class="font-bold text-green-900">recsys
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/site.html" class="font-bold text-green-900">site
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/www.html" class="font-bold text-green-900">www
            </a><span class="">3</span>
        </li>
    </ul>
</div>
</aside><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
  <div class="mx-auto mt-auto w-screen px-4 bg-green-500 mt-4 md:py-8">
    <div class="md:invisible md:hidden max-w-8xl"><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>







<script data-goatcounter="https://tusharc.goatcounter.com/count" async src="//gc.zgo.at/count.js">
</script>
</body>

</html>