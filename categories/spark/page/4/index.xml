<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on Tushar Chandra</title>
    <link>/categories/spark.html</link>
    <description>Recent content in spark on Tushar Chandra</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jun 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/categories/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Paper] What is AI Literacy? Competencies and Design Considerations</title>
      <link>/papers/what_is_ai_literacy_long.html</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/what_is_ai_literacy_long.html</guid>
      <description>&lt;p&gt;What does it mean to be AI literate? This work, which received a Best Paper Honorable Mention at CHI 2020, first defines &lt;em&gt;AI literacy&lt;/em&gt; in terms of its core competencies, then discusses considerations for the design of AI systems.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Personal news: I got promoted!</title>
      <link>/posts/promotion_senior.html</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/promotion_senior.html</guid>
      <description>&lt;p&gt;I was recently promoted to senior data scientist! This is a short post with some details and reflection.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>My review of &#39;Weapons of Math Destruction&#39;</title>
      <link>/books/weapons_math_destruction.html</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/books/weapons_math_destruction.html</guid>
      <description>&lt;p&gt;This is my review of &lt;em&gt;Weapons of Math Destruction&lt;/em&gt; by Dr. Cathy O&amp;rsquo;Neil. I found it to be a clearly written book, explaining many of the problems with &amp;ldquo;big data&amp;rdquo; systems: lack of access to proper data, problems that come from the scale of these systems, and vicious feedback loops.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (August 9 - 15)</title>
      <link>/what_i_read/20200815.html</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200815.html</guid>
      <description>&lt;p&gt;I&amp;rsquo;m trying to put together my first submission for a conference CFP: &lt;a href=&#34;https://pymc-devs.github.io/pymcon//cfp&#34;&gt;PyMCon&lt;/a&gt;, an all-virtual conference happening this November. This week, I sought out a lot of blog posts about this to help.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Two Computational Models for Analyzing Political Attention in Social Media</title>
      <link>/papers/modeling_political_attention_hemphill.html</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/modeling_political_attention_hemphill.html</guid>
      <description>&lt;p&gt;What are members of Congress tweeting about, and how can we use machine learning to infer this? In this ICWSM 2020 paper, the researchers try out both supervised and unsupervised learning on all the tweets from members of the 115th Congress (Jan. 2017 - Jan. 2019).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Understanding deep learning requires rethinking generalization</title>
      <link>/papers/understanding_dl_generalization_zhang.html</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/understanding_dl_generalization_zhang.html</guid>
      <description>&lt;p&gt;This Google Brain paper from ICLR 2017 tackles the question of &lt;em&gt;generalization&lt;/em&gt; in neural networks. What causes a network that performs well on training data to also perform well on testing data? (Answer: ¯\_(ツ)_/¯)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (August 2 - 8)</title>
      <link>/what_i_read/20200808.html</link>
      <pubDate>Sat, 08 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200808.html</guid>
      <description>&lt;p&gt;A few articles from Pointer this week, an &lt;em&gt;amazing&lt;/em&gt; post titled &amp;ldquo;System Design for Advanced Beginners,&amp;rdquo; and some blogging advice.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] An Experimental Study of Structural Diversity in Social Networks</title>
      <link>/papers/experimental_study_structural_diversity_su.html</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/experimental_study_structural_diversity_su.html</guid>
      <description>&lt;p&gt;In a social network, structural diversity is a measure of how (dis)similar one&amp;rsquo;s social connections are. It&amp;rsquo;s positively correlated with engagement, but the mechanism behind this is unknown. This work experimentally alters structural diversity for new Twitter users, studying whether or not it affects user retention.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Local Trends in Global Music Streaming</title>
      <link>/papers/local_trends_streaming_way.html</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/local_trends_streaming_way.html</guid>
      <description>&lt;p&gt;Spotify makes a global music catalog available to subscribers around the world. Historically, that&amp;rsquo;s meant different countries have more access to each other&amp;rsquo;s music. How does that hold up in 5.5 years of Spotify streaming data?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 26 - August 1)</title>
      <link>/what_i_read/20200801.html</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200801.html</guid>
      <description>&lt;p&gt;This week&amp;rsquo;s articles include &amp;ldquo;Create space for others&amp;rdquo; by Will Larson, &amp;ldquo;What does sponsorship look like?&amp;rdquo; by Lara Hogan, and &amp;ldquo;Be Impatient&amp;rdquo; by Ben Kuhn.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Generative Models for Effective ML on Private, Decentralized Datasets</title>
      <link>/papers/generative_models_augenstein.html</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/generative_models_augenstein.html</guid>
      <description>&lt;p&gt;How do you build and debug machine learning models when you don&amp;rsquo;t have access to the raw data? Maybe it&amp;rsquo;s sensitive information, or that it&amp;rsquo;s stored on user devices. This Google paper from ICLR 2020 proposes using &lt;em&gt;generative models&lt;/em&gt; as a privacy-preserving stand-in for user data.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 19 - 25)</title>
      <link>/what_i_read/20200725.html</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200725.html</guid>
      <description>&lt;p&gt;I&amp;rsquo;m spending a lot of time reading Cathy O&amp;rsquo;Neil&amp;rsquo;s &lt;em&gt;Weapons of Math Destruction&lt;/em&gt;, which is excellent. This week&amp;rsquo;s articles include advice for grad students and some advice on software engineering.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Papers] Two more papers from the ICML Participatory Approaches to ML workshop</title>
      <link>/papers/icml_workshop_papers_2.html</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/icml_workshop_papers_2.html</guid>
      <description>&lt;p&gt;Two more papers in the &lt;a href=&#34;https://participatoryml.github.io/&#34;&gt;Participatory Approaches to Machine Learning&lt;/a&gt; workshop at ICML 2020. These are more directly about participation: &lt;em&gt;Participation is not a Design Fix for Machine Learning&lt;/em&gt; and &lt;em&gt;What If I Don&amp;rsquo;t Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Papers] Two recommender systems papers from the ICML Participatory Approaches to ML workshop</title>
      <link>/papers/icml_workshop_papers.html</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/icml_workshop_papers.html</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://participatoryml.github.io/&#34;&gt;Participatory Approaches to Machine Learning&lt;/a&gt; workshop at ICML 2020 caught my attention, and so I read two papers on recommender systems that came out of it: &lt;em&gt;Deconstructing the Filter Bubble: User Decision-Making and Recommender Systems&lt;/em&gt; and &lt;em&gt;Designing Recommender Systems with Reachability in Mind&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] What are you optimizing for? Aligning Recommender Systems with Human Values</title>
      <link>/papers/aligning_recommender_human_values_stray.html</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/aligning_recommender_human_values_stray.html</guid>
      <description>&lt;p&gt;How can recommender systems better align to human values, like fairness, diversity, or equity? This paper, from the ICML Participatory Approaches to ML workshop, discusses approaches to answering this question.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 12 - July 18)</title>
      <link>/what_i_read/20200718.html</link>
      <pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200718.html</guid>
      <description>&lt;p&gt;This week, all the blog posts and articles I read came from &lt;a href=&#34;https://pointer.io&#34;&gt;Pointer&lt;/a&gt;. I spent most of my free time finishing up the book &lt;em&gt;Twenty Six Words&lt;/em&gt; (highly recommend!) and then starting &lt;em&gt;Weapons of Math Destruction&lt;/em&gt; by Cathy O&amp;rsquo;Neil.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The future of Section 230</title>
      <link>/books/twenty_six_words_4.html</link>
      <pubDate>Fri, 17 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/books/twenty_six_words_4.html</guid>
      <description>&lt;p&gt;What comes next for Section 230? What comes next for the platforms who have used Section 230 as a shield for so long?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Internet Exceptionalism</title>
      <link>/books/twenty_six_words_3.html</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/books/twenty_six_words_3.html</guid>
      <description>&lt;p&gt;In my second-to-last post on Section 230, I discuss the idea of internet exceptionalism&amp;mdash;how, in passing Section 230, Congress decided that the internet should be different than other publishing mediums.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 5 - July 11)</title>
      <link>/what_i_read/20200711.html</link>
      <pubDate>Sat, 11 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200711.html</guid>
      <description>&lt;p&gt;This week, I watched a few talks from SciPy 2020 and continued my reading on &lt;em&gt;Twenty-Six Words&lt;/em&gt;; this post mostly contains the talks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (June 28 - July 4)</title>
      <link>/what_i_read/20200704.html</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200704.html</guid>
      <description>&lt;p&gt;This week&amp;rsquo;s reading was all over the place: a talk on Docker and Python for data science, authorial intent in code, the book &lt;em&gt;Clean Code&lt;/em&gt;, and an essay on NPM.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
