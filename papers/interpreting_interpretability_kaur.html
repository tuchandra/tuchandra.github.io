<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <title>
        [Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning - Tushar Chandra
      </title>
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" />
  
  <meta name="description" content="I&amp;rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.
" />
  <meta name="generator" content="Hugo 0.70.0 with theme pure" />
  <title>[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning - Tushar Chandra</title>
  

  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
  <meta property="og:title" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning" />
<meta property="og:description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/papers/interpreting_interpretability_kaur.html" />
<meta property="article:published_time" content="2020-03-17T00:00:00-05:00" />
<meta property="article:modified_time" content="2020-03-17T00:00:00-05:00" />
<meta itemprop="name" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning">
<meta itemprop="description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.">
<meta itemprop="datePublished" content="2020-03-17T00:00:00-05:00" />
<meta itemprop="dateModified" content="2020-03-17T00:00:00-05:00" />
<meta itemprop="wordCount" content="1140">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning"/>
<meta name="twitter:description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them."/>
</head>
  </head>
  

  <body class="main-center theme-blue" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader">
    <div class="slimContent">
      <div class="navbar-header">
        <div class="profile-block text-center">
          <a id="avatar" href="/">
            <img class="img-circle" src="/headshot.jpg" width="200" height="200">
          </a>
          <h2 id="name" class="hidden-xs hidden-sm"><b>Tushar Chandra</b></h2>
          <h3 id="title" class="hidden-xs hidden-sm hidden-md">Data Scientist</h3>
          <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Chicago, IL</small>
        </div>

        
        <nav id="mobile-navbar" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
          <ul class="mobile-nav">
              <a href="/">
                <li class="menu-item-home">
                    <i class="icon icon-home-fill"></i>
                  <span class="menu-title"><br>Home</span>
                </li>
              </a>
              <a href="/about">
                <li class="menu-item-about">
                    <i class="icon icon-cup-fill"></i>
                  <span class="menu-title"><br>About</span>
                </li>
              </a>
              <a href="/resume">
                <li class="menu-item-resume">
                    <i class="icon icon-file"></i>
                  <span class="menu-title"><br>Resume</span>
                </li>
              </a>
              <a href="/reading">
                <li class="menu-item-reading">
                    <i class="icon icon-shu-fill"></i>
                  <span class="menu-title"><br>Reading</span>
                </li>
              </a>
              <a href="/categories.html">
                <li class="menu-item-categories">
                    <i class="icon icon-folder-open"></i>
                  <span class="menu-title"><br>Categories</span>
                </li>
              </a>
              <a href="/posts.html">
                <li class="menu-item-archives">
                    <i class="icon icon-archives-fill"></i>
                  <span class="menu-title"><br>Archives</span>
                </li>
              </a>

          </ul>
        </nav>
      </div>
      <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="nav navbar-nav main-nav">
            <li class="menu-item menu-item-home">
                <a href="/">
                    <i class="icon icon-home-fill"></i>
                  <span class="menu-title">Home</span>
                </a>
            </li>
            <li class="menu-item menu-item-about">
                <a href="/about">
                    <i class="icon icon-cup-fill"></i>
                  <span class="menu-title">About</span>
                </a>
            </li>
            <li class="menu-item menu-item-resume">
                <a href="/resume">
                    <i class="icon icon-file"></i>
                  <span class="menu-title">Resume</span>
                </a>
            </li>
            <li class="menu-item menu-item-reading">
                <a href="/reading">
                    <i class="icon icon-shu-fill"></i>
                  <span class="menu-title">Reading</span>
                </a>
            </li>
            <li class="menu-item menu-item-categories">
                <a href="/categories.html">
                    <i class="icon icon-folder-open"></i>
                  <span class="menu-title">Categories</span>
                </a>
            </li>
            <li class="menu-item menu-item-archives">
                <a href="/posts.html">
                    <i class="icon icon-archives-fill"></i>
                  <span class="menu-title">Archives</span>
                </a>
            </li>

        </ul>
      </nav>
    </div>
  </header>
<aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <div class="widget">
    <h3 class="widget-title"> Categories</h3>
    <div class="widget-body">
        <ul class="category-list">
            <li class="category-list-item"><a href="/categories/books.html" class="category-list-link">books</a><span class="category-list-count">5</span></li>
            <li class="category-list-item"><a href="/categories/chi2020.html" class="category-list-link">chi2020</a><span class="category-list-count">19</span></li>
            <li class="category-list-item"><a href="/categories/general.html" class="category-list-link">general</a><span class="category-list-count">32</span></li>
            <li class="category-list-item"><a href="/categories/papers.html" class="category-list-link">papers</a><span class="category-list-count">45</span></li>
            <li class="category-list-item"><a href="/categories/projects.html" class="category-list-link">projects</a><span class="category-list-count">7</span></li>
            <li class="category-list-item"><a href="/categories/self.html" class="category-list-link">self</a><span class="category-list-count">3</span></li>
            <li class="category-list-item"><a href="/categories/spark.html" class="category-list-link">spark</a><span class="category-list-count">13</span></li>
            <li class="category-list-item"><a href="/categories/what-i-read.html" class="category-list-link">what-i-read</a><span class="category-list-count">28</span></li>
        </ul>
    </div>
</div>
<div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
        <ul class="recent-post-list list-unstyled no-thumbnail">
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/fragile_masculinity_online_harassment_rubin.html" class="title">[Paper] Fragile Masculinity: Men, Gender, and Online Harassment</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-06-15 00:00:00 -0500 CDT" itemprop="datePublished">2020-06-15</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/facebook_self_reported_survey_ernala.html" class="title">[Paper] How Well Do People Report Time Spent on Facebook?: An Evaluation of Established Survey Questions with Recommendations</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-06-14 00:00:00 -0500 CDT" itemprop="datePublished">2020-06-14</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/what_i_read/20200613.html" class="title">What I read this week (June 7 - 13)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-06-13 00:00:00 -0500 CDT" itemprop="datePublished">2020-06-13</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/information_operations_blm_arif.html" class="title">[Paper] Acting the Part: Examining Information Operations Within #BlackLivesMatter Discourse</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-06-10 00:00:00 -0500 CDT" itemprop="datePublished">2020-06-10</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/critical_race_theory_ogburu.html" class="title">[Paper] Critical Race Theory for HCI</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-06-08 00:00:00 -0500 CDT" itemprop="datePublished">2020-06-08</time>
                    </p>
                </div>
            </li>
        </ul>
    </div>
</div>
  </div>
</aside>

    
    
<main class="main" role="main"><div class="content">
  <article id="-" class="article article-type-" itemscope
    itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      <h1 itemprop="name">
  <a
    class=""
    href="/papers/interpreting_interpretability_kaur.html"
    >[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning</a
  >
</h1>

      <div class="article-meta">
        <span class="article-date">
  <i class="icon icon-calendar-check"></i>
<a href="/papers/interpreting_interpretability_kaur.html">
  <time datetime="2020-03-17 00:00:00 -0500 CDT" itemprop="datePublished">2020-03-17</time>
</a>
</span><span class="article-category">
  <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/papers.html"> papers, </a>
    <a class="article-category-link" href="/categories/chi2020.html"> chi2020, </a>
</span>

        
      </div>
    </div>
    <div class="article-entry marked-body js-toc-content" itemprop="articleBody">
      <p>I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.</p>
<p><strong>Authors</strong>: Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, Jennifer Wortman Vaughan</p>
<p><strong>Link</strong>: on Kaur&rsquo;s <a href="http://www-personal.umich.edu/~harmank/Papers/CHI2020_Interpretability.pdf">website</a> (to appear in CHI 2020)</p>
<h2 id="summary">Summary</h2>
<p>From the abstract:</p>
<blockquote>
<p>Interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study &hellip; the InterpretML implementation of GAMs and the SHAP Python package.</p>
</blockquote>
<p>Super interesting! They&rsquo;re right: I&rsquo;ve written about interpretability tools before (see <a href="/papers/model_cards_mitchell.html">Model Cards for Model Reporting</a>, <a href="/papers/proposed_guidelines_xai_hall.html">Proposed Guidelines for the Responsible Use of Explainable Machine Learning</a>), but only informally thought about how well they work in practice. It&rsquo;s all been &ldquo;that sounds reasonable&rdquo; or &ldquo;I don&rsquo;t know that this would work,&rdquo; so this paper is timely.</p>
<blockquote>
<p>Our results indicate that data scientists over-trust and misuse interpretability tools.</p>
</blockquote>
<p>Uh oh.</p>
<h2 id="study-interviews-and-contextual-inquiry">Study: interviews and contextual inquiry</h2>
<p>The authors conduced semi-structured pilot interviews with six data scientists at a &ldquo;large technology company&rdquo; (hmm &hellip;). The goal was to &ldquo;surface common issues that arise when building and evaluating ML models.&rdquo; They identified the following themes:</p>
<figure>
    <img src="interpreting_interpretability_kaur_img1.png"/> 
</figure>

<p><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p>The researchers gave 11 people data scientist-like folks a Jupyter notebook with a dataset (Adult Income dataset), ML model, and interpretability technique (GAMs, which is inherently interpretable, and SHAP, which is a post-hoc technique). They were able to explore the notebook themselves, then were asked questions about the dataset (&ldquo;what are the most important features according to this explanation?&quot;) and about the issues in Table 1 above.</p>
<p><strong>Results</strong>: &ldquo;Our contextual inquiry reveals a misalignment between data scientists&rsquo; understanding of interpretability tools and these tools&rsquo; intended use.&rdquo; This misalignment manifests itself in the following ways:</p>
<ul>
<li>Overtrusting tools: using interpretability tools to rationalize suspicious observations, or because they hadn&rsquo;t seen them before. &ldquo;It&rsquo;s very transparent, and that makes me trust it more.&rdquo;</li>
<li>Undertrusting tools: when they don&rsquo;t provide the expected clarity. &ldquo;It&rsquo;s a visualization. There was no interpretation provided here.&rdquo;</li>
<li>A general lack of understanding of how SHAP importance scores are calculated</li>
</ul>
<p><em>Social context</em> was important, too: one participant said &ldquo;this is a pretty popular tool &hellip; so it made sense, I suppose&rdquo; in regards to SHAP, rationalizing explanations that they didn&rsquo;t fully understand. Additionally, the visualizations themselves were sometimes misleading (by not explaining or giving appropriate context for the meaning of the values they presented).</p>
<h2 id="study-survey">Study: survey</h2>
<p>The goal of this was to quantify the previous findings at a larger scale. Participants were asked the same questions as during the interviews, but this time shown the results of exploration commands and asked questions about the dataset and model. The questions covered &ldquo;global feature importance, the relationship between age and the output variable, &hellip; the local explanation for a correctly classified data point, and the local explanation for a misclassified data point.&rdquo; Participants were asked a variety of questions, from multiple-choice with an objectively correct answer to open-ended questions designed to test participants&rsquo; understanding.</p>
<p>Participants were assigned to either GAM or SHAP, as before, but this time each was stratified into &ldquo;normal&rdquo; (where the viz outputs were correct) and &ldquo;manipulated&rdquo; (where features were rearranged, so the least important features were displayed as most important). Participants in the &ldquo;manipulated&rdquo; conditions were less confident that the results were reasonable, thankfully.</p>
<h2 id="factors-that-affect-willingness-to-deploy">Factors that affect willingness to deploy</h2>
<p>One part of the survey asked what makes a model ready for deployment. The themes were:</p>
<ul>
<li><strong>Intuition</strong>: most participants relied heavily on past experience, sometimes suggesting that they&rsquo;d ask customers to trust their judgment.</li>
<li><strong>Superficial evaluation of experiments</strong>: using the <em>existence</em> of visualizations to convince themselves. &ldquo;The charts in combination help you infer reasonable things about the model&rdquo; or &ldquo;the top features are reasonable.&rdquo;</li>
<li><strong>Perceived suspicions</strong>: some participants were suspicious of the models (&ldquo;what the heck is happening with 37/38 year olds?&quot;) or the tests (lack of confidence intervals, overall test scores, etc.). These were the ones who used interpretability tools correctly, to uncover issues that needed further study.</li>
</ul>
<p>It&rsquo;s interesting, but not entirely surprising, how much participants rely on their intuition here. They often used the visualizations to confirm their priors, instead of thinking critically about the information presented. The authors call this &ldquo;a mismatch between participants&rsquo; mental models [what users think] of the tools and the conceptual models [what designers think] of the tools.&rdquo; This was supported by participants&rsquo; explanations of the technical details of what the tools provided.</p>
<blockquote>
<p>These results indicate that participants did not fully understand the visualizations output by the interpretability tools. However, despite this, they had high expectations for these visualizations, above and beyond these tools&rsquo; capabilities.</p>
</blockquote>
<p>Wouldn&rsquo;t it be great if model evaluation were easy? This is a good example of something I&rsquo;ve encountered a lot in practice: that it&rsquo;s really easy to convince yourself of the <em>wrong</em> thing based on the mere <em>presence</em> of an explanation. I&rsquo;m certainly guilty of taking explanations at face value when I later found them to be wrong (based on a bug in my data, model, or visualization).</p>
<h2 id="implications-for-design-and-other-thoughts">Implications for design and other thoughts</h2>
<p>The authors write that &ldquo;research on interpretability in the ML and HCI communities has evolved somewhat independently.&rdquo; It&rsquo;s not clear how machine learning practitioners use interpretability tools in practice, which is a gap that this paper helped to fill. One of the key findings was that data scientists were <em>unable</em> to fully understand the outputs of existing tools.</p>
<p>There&rsquo;s clearly a gap between what the tools are built for and how they&rsquo;re used. Perhaps this means the tools aren&rsquo;t designed to adequately meet users&rsquo; needs, and this is what a human-centered approach might suggest. I suspect, however, that a lot of people in the ML community would take the opposite persepctive and say that it&rsquo;s the <em>users</em> (data scientists) who should learn how to use them properly.</p>
<p>The question of &ldquo;how people use tools&rdquo; is incredibly important. Interpretability is a hot topic, and one that I&rsquo;m particularly interested in, and it&rsquo;s great to read a paper that studies how (in)effective interpretability tools are in practice. This helps me to believe in using inherently interpretable models over post-hoc explanations when possible (see <a href="https://www.nature.com/articles/s42256-019-0048-x">Rudin in Nature</a>).</p>
<p>That&rsquo;s not to say that interpretability tools are bad, of course; but there&rsquo;s clearly a gap here that needs to be addressed. This is consistent with my experience trying to use them, too. Some researchers propose interactive tools that let users dig into explanations, or that engage deliberative reasoning skills to slow-down decision making. Whatever it is, I&rsquo;m excited to see where the research goes.</p>
    </div>
    <div class="article-footer">
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/posts/is_twitter_real_life.html" title="Is Twitter real life?"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;Older</span></a>
            </li>
            <li class="next">
                <a href="/books/network_propaganda_2.html"
                    title="Network Propaganda, part 2"><span>Newer&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>


</main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
<ul class="social-links">
    <li><a href="https://github.com/tuchandra" target="_blank" title="github" data-toggle=tooltip data-placement=top >
            <i class="icon icon-github"></i></a></li>
    <li><a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin" data-toggle=tooltip data-placement=top >
            <i class="icon icon-linkedin"></i></a></li>
    <li><a href="/index.xml" target="_blank" title="rss" data-toggle=tooltip data-placement=top >
            <i class="icon icon-rss"></i></a></li>
</ul>
  <div class="copyright">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">
        Theme: <a href="https://github.com/xiaoheiAh/hugo-theme-pure" target="_blank">Hugo Pure</a>.
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js"></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>

  </body>
</html>
