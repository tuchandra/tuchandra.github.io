<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <title>
    [Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning - Tushar Chandra
    </title>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" /><meta name="description" content="I&amp;rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.
" />
  <meta name="generator" content="Hugo 0.70.0" />
  <title>[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning - Tushar Chandra</title>

  
  
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">

  <meta property="og:title" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning" />
<meta property="og:description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/papers/interpreting_interpretability_kaur.html" />
<meta property="article:published_time" content="2020-03-17T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-03-17T00:00:00+00:00" />
<meta itemprop="name" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning">
<meta itemprop="description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.">
<meta itemprop="datePublished" content="2020-03-17T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2020-03-17T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1140">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning"/>
<meta name="twitter:description" content="I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them."/>
</head>
</head>



<body class="h-screen flex flex-col justify-between" itemscope itemtype="http://schema.org/WebPage"><header class="w-screen bg-green-500" itemscope itemtype="http://schema.org/WPHeader">
  <div class="flex max-w-8xl container mx-auto">
    <div class="hidden sm:inline flex items-center">
      <a href="/">
        <img class="rounded-full m-1 md:m-4" src="/headshot.jpg" width="100" height="100">
      </a>
    </div>
    <div class="w-full px-4 flex flex-col lg:flex-row justify-between lg:items-center my-4">
      <div class="xl:flex-grow">
        <a href="/">
          <span class="text-lg sm:text-2xl md:text-3xl font-semibold">Tushar Chandra</span>
          <span class="hidden pl-4 lg:inline"><br></span>
          <span class="text-sm md:text-xl font-thin pl-4 md:pl-0 lg:text-xl">Data Scientist / Chicago, IL
          </span>
        </a>
      </div>
      <nav class="" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="flex lg:justify-between">
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/about">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-mug-hot"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">About</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/resume">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-file"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Resume</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/reading">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-book-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Reading</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/categories.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-folder-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Categories</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/posts.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-archive"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Archives</span>
              </a>
            </p>
          </li>

        </ul>

      </nav>
    </div>

  </div>
</header>
  <div class="container mx-auto max-w-8xl px-4 flex flex-row flex-grow">
    <div class="w-full md:w-3/4">
      
<main class="main" role="main"><div class="content container mx-auto max-w-6xl">
  <article id="-" class="" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="pt-4">
      <span class="font-semibold text-3xl"><h1 itemprop="name">
  <a class="" href="/papers/interpreting_interpretability_kaur.html">[Paper] Interpreting Interpretability: Understanding Data Scientists&#39; Use of Interpretability Tools for Machine Learning</a>
</h1>
      </span>
      <div class="pb-4"><i class="fas fa-calendar-check text-gray-500 pr-1"></i>
<time datetime="2020-03-17 00:00:00 &#43;0000 UTC" class="text-sm text-gray-600"
  itemprop="datePublished">2020-03-17</time>
<span class="text-sm text-gray-600" itemprop="wordCount">
	<i class="fas fa-pencil-alt text-gray-500 pl-4 pr-2"></i>1140 words
</span><i class="fas fa-folder-open text-gray-500 pl-4 pr-1"></i>
<a class="text-sm text-gray-600" href=" /categories/papers.html"> papers, </a>
<a class="text-sm text-gray-600" href=" /categories/chi2020.html"> chi2020, </a>
<span class="article-category text-sm text-gray-600 pl-4">
  <i class="fa fa-users "></i>
  Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, Jennifer Wortman Vaughan
</span>
      </div>
    </div>
    <div class="rich-text" itemprop="articleBody">
      <p>I&rsquo;m hoping to get back into a routine of reading papers after a crazy couple of weeks; this is the first of hopefully many. This is a paper to appear at CHI 2020 (with an Honorable Mention!) about the use of interpretability tools in machine learning, and how (uh oh) data scientists tend to over-trust them.</p>
<p><strong>Authors</strong>: Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, Jennifer Wortman Vaughan</p>
<p><strong>Link</strong>: on Kaur&rsquo;s <a href="http://www-personal.umich.edu/~harmank/Papers/CHI2020_Interpretability.pdf">website</a> (to appear in CHI 2020)</p>
<h2 id="summary">Summary</h2>
<p>From the abstract:</p>
<blockquote>
<p>Interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study &hellip; the InterpretML implementation of GAMs and the SHAP Python package.</p>
</blockquote>
<p>Super interesting! They&rsquo;re right: I&rsquo;ve written about interpretability tools before (see <a href="/papers/model_cards_mitchell.html">Model Cards for Model Reporting</a>, <a href="/papers/proposed_guidelines_xai_hall.html">Proposed Guidelines for the Responsible Use of Explainable Machine Learning</a>), but only informally thought about how well they work in practice. It&rsquo;s all been &ldquo;that sounds reasonable&rdquo; or &ldquo;I don&rsquo;t know that this would work,&rdquo; so this paper is timely.</p>
<blockquote>
<p>Our results indicate that data scientists over-trust and misuse interpretability tools.</p>
</blockquote>
<p>Uh oh.</p>
<h2 id="study-interviews-and-contextual-inquiry">Study: interviews and contextual inquiry</h2>
<p>The authors conduced semi-structured pilot interviews with six data scientists at a &ldquo;large technology company&rdquo; (hmm &hellip;). The goal was to &ldquo;surface common issues that arise when building and evaluating ML models.&rdquo; They identified the following themes:</p>
<figure>
    <img src="interpreting_interpretability_kaur_img1.png"/> 
</figure>

<p><br/><br/></p>
<p>The researchers gave 11 people data scientist-like folks a Jupyter notebook with a dataset (Adult Income dataset), ML model, and interpretability technique (GAMs, which is inherently interpretable, and SHAP, which is a post-hoc technique). They were able to explore the notebook themselves, then were asked questions about the dataset (&ldquo;what are the most important features according to this explanation?&quot;) and about the issues in Table 1 above.</p>
<p><strong>Results</strong>: &ldquo;Our contextual inquiry reveals a misalignment between data scientists&rsquo; understanding of interpretability tools and these tools&rsquo; intended use.&rdquo; This misalignment manifests itself in the following ways:</p>
<ul>
<li>Overtrusting tools: using interpretability tools to rationalize suspicious observations, or because they hadn&rsquo;t seen them before. &ldquo;It&rsquo;s very transparent, and that makes me trust it more.&rdquo;</li>
<li>Undertrusting tools: when they don&rsquo;t provide the expected clarity. &ldquo;It&rsquo;s a visualization. There was no interpretation provided here.&rdquo;</li>
<li>A general lack of understanding of how SHAP importance scores are calculated</li>
</ul>
<p><em>Social context</em> was important, too: one participant said &ldquo;this is a pretty popular tool &hellip; so it made sense, I suppose&rdquo; in regards to SHAP, rationalizing explanations that they didn&rsquo;t fully understand. Additionally, the visualizations themselves were sometimes misleading (by not explaining or giving appropriate context for the meaning of the values they presented).</p>
<h2 id="study-survey">Study: survey</h2>
<p>The goal of this was to quantify the previous findings at a larger scale. Participants were asked the same questions as during the interviews, but this time shown the results of exploration commands and asked questions about the dataset and model. The questions covered &ldquo;global feature importance, the relationship between age and the output variable, &hellip; the local explanation for a correctly classified data point, and the local explanation for a misclassified data point.&rdquo; Participants were asked a variety of questions, from multiple-choice with an objectively correct answer to open-ended questions designed to test participants&rsquo; understanding.</p>
<p>Participants were assigned to either GAM or SHAP, as before, but this time each was stratified into &ldquo;normal&rdquo; (where the viz outputs were correct) and &ldquo;manipulated&rdquo; (where features were rearranged, so the least important features were displayed as most important). Participants in the &ldquo;manipulated&rdquo; conditions were less confident that the results were reasonable, thankfully.</p>
<h2 id="factors-that-affect-willingness-to-deploy">Factors that affect willingness to deploy</h2>
<p>One part of the survey asked what makes a model ready for deployment. The themes were:</p>
<ul>
<li><strong>Intuition</strong>: most participants relied heavily on past experience, sometimes suggesting that they&rsquo;d ask customers to trust their judgment.</li>
<li><strong>Superficial evaluation of experiments</strong>: using the <em>existence</em> of visualizations to convince themselves. &ldquo;The charts in combination help you infer reasonable things about the model&rdquo; or &ldquo;the top features are reasonable.&rdquo;</li>
<li><strong>Perceived suspicions</strong>: some participants were suspicious of the models (&ldquo;what the heck is happening with 37/38 year olds?&quot;) or the tests (lack of confidence intervals, overall test scores, etc.). These were the ones who used interpretability tools correctly, to uncover issues that needed further study.</li>
</ul>
<p>It&rsquo;s interesting, but not entirely surprising, how much participants rely on their intuition here. They often used the visualizations to confirm their priors, instead of thinking critically about the information presented. The authors call this &ldquo;a mismatch between participants&rsquo; mental models [what users think] of the tools and the conceptual models [what designers think] of the tools.&rdquo; This was supported by participants&rsquo; explanations of the technical details of what the tools provided.</p>
<blockquote>
<p>These results indicate that participants did not fully understand the visualizations output by the interpretability tools. However, despite this, they had high expectations for these visualizations, above and beyond these tools&rsquo; capabilities.</p>
</blockquote>
<p>Wouldn&rsquo;t it be great if model evaluation were easy? This is a good example of something I&rsquo;ve encountered a lot in practice: that it&rsquo;s really easy to convince yourself of the <em>wrong</em> thing based on the mere <em>presence</em> of an explanation. I&rsquo;m certainly guilty of taking explanations at face value when I later found them to be wrong (based on a bug in my data, model, or visualization).</p>
<h2 id="implications-for-design-and-other-thoughts">Implications for design and other thoughts</h2>
<p>The authors write that &ldquo;research on interpretability in the ML and HCI communities has evolved somewhat independently.&rdquo; It&rsquo;s not clear how machine learning practitioners use interpretability tools in practice, which is a gap that this paper helped to fill. One of the key findings was that data scientists were <em>unable</em> to fully understand the outputs of existing tools.</p>
<p>There&rsquo;s clearly a gap between what the tools are built for and how they&rsquo;re used. Perhaps this means the tools aren&rsquo;t designed to adequately meet users&rsquo; needs, and this is what a human-centered approach might suggest. I suspect, however, that a lot of people in the ML community would take the opposite persepctive and say that it&rsquo;s the <em>users</em> (data scientists) who should learn how to use them properly.</p>
<p>The question of &ldquo;how people use tools&rdquo; is incredibly important. Interpretability is a hot topic, and one that I&rsquo;m particularly interested in, and it&rsquo;s great to read a paper that studies how (in)effective interpretability tools are in practice. This helps me to believe in using inherently interpretable models over post-hoc explanations when possible (see <a href="https://www.nature.com/articles/s42256-019-0048-x">Rudin in Nature</a>).</p>
<p>That&rsquo;s not to say that interpretability tools are bad, of course; but there&rsquo;s clearly a gap here that needs to be addressed. This is consistent with my experience trying to use them, too. Some researchers propose interactive tools that let users dig into explanations, or that engage deliberative reasoning skills to slow-down decision making. Whatever it is, I&rsquo;m excited to see where the research goes.</p>
      <p><i class="fas fa-square font-green-800"></i></p>
    </div>
    <div class="font-semibold text-green-800 pt-4">
      <a href="/"><i class="fas fa-arrow-left"></i> Return home</a>
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/posts/is_twitter_real_life.html" title="Is Twitter real life?"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;</span></a>
            </li>
            <li class="next">
                <a href="/books/network_propaganda_2.html"
                    title="Network Propaganda, part 2"><span>&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>

</main>
    </div>
    <div class="hidden w-0 md:block md:w-1/4 md:pt-8 md:pl-12"><aside class="" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="pb-8">
    <h3 class="font-semibold text-xl">Categories</h3>
    <ul class="">
        <li class="">+ <a href="/categories/books.html" class="font-bold text-green-900">books
            </a><span class="">11</span>
        </li>
        <li class="">+ <a href="/categories/chi2020.html" class="font-bold text-green-900">chi2020
            </a><span class="">19</span>
        </li>
        <li class="">+ <a href="/categories/general.html" class="font-bold text-green-900">general
            </a><span class="">34</span>
        </li>
        <li class="">+ <a href="/categories/papers.html" class="font-bold text-green-900">papers
            </a><span class="">53</span>
        </li>
        <li class="">+ <a href="/categories/projects.html" class="font-bold text-green-900">projects
            </a><span class="">7</span>
        </li>
        <li class="">+ <a href="/categories/self.html" class="font-bold text-green-900">self
            </a><span class="">3</span>
        </li>
        <li class="">+ <a href="/categories/spark.html" class="font-bold text-green-900">spark
            </a><span class="">34</span>
        </li>
        <li class="">+ <a href="/categories/what-i-read.html" class="font-bold text-green-900">what-i-read
            </a><span class="">35</span>
        </li>
    </ul>
</div>
<div class="pb-12">
    <h3 class="font-semibold text-xl">Recent Posts</h3>
    <ul class="recent-post-list list-unstyled no-thumbnail">
        <li class="pb-4">
            <p>
                <a href="/papers/understanding_dl_generalization_zhang.html" class="font-bold text-green-900">[Paper] Understanding deep learning requires rethinking generalization</a>
                <time datetime="2020-08-12 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-08-12
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/what_i_read/20200808.html" class="font-bold text-green-900">What I read this week (August 2 - 8)</a>
                <time datetime="2020-08-08 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-08-08
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/experimental_study_structural_diversity_su.html" class="font-bold text-green-900">[Paper] An Experimental Study of Structural Diversity in Social Networks</a>
                <time datetime="2020-08-04 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-08-04
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/local_trends_streaming_way.html" class="font-bold text-green-900">[Paper] Local Trends in Global Music Streaming</a>
                <time datetime="2020-08-02 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-08-02
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/what_i_read/20200801.html" class="font-bold text-green-900">What I read this week (July 26 - August 1)</a>
                <time datetime="2020-08-01 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-08-01
                </time>
            </p>

        </li>
    </ul>
</div>
</aside><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
  <div class="mx-auto w-screen px-4 bg-green-500 mt-4 md:py-8">
    <div class="md:invisible md:hidden max-w-8xl"><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js"></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>


<script data-goatcounter="https://tusharc.goatcounter.com/count" async src="//gc.zgo.at/count.js">
</script>
</body>

</html>