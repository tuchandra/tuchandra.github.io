<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <title>
    [Paper] On the Legal Compatibility of Fairness Definitions - Tushar Chandra
    </title>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" /><meta name="description" content="Fairness in machine learning is typically concerned with ideas like discrimination, disparate impact or treatment, or protected classes. This paper describes how the definitions being used in ML aren&amp;rsquo;t always compatible with definitions in the legal system.
" />
  <meta name="generator" content="Hugo 0.70.0" />
  <title>[Paper] On the Legal Compatibility of Fairness Definitions - Tushar Chandra</title>

  
  
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">

  <meta property="og:title" content="[Paper] On the Legal Compatibility of Fairness Definitions" />
<meta property="og:description" content="Fairness in machine learning is typically concerned with ideas like discrimination, disparate impact or treatment, or protected classes. This paper describes how the definitions being used in ML aren&rsquo;t always compatible with definitions in the legal system." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/papers/legal_compatibility_fairness_definitions_xiang.html" />
<meta property="article:published_time" content="2021-01-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-01-07T00:00:00+00:00" />
<meta itemprop="name" content="[Paper] On the Legal Compatibility of Fairness Definitions">
<meta itemprop="description" content="Fairness in machine learning is typically concerned with ideas like discrimination, disparate impact or treatment, or protected classes. This paper describes how the definitions being used in ML aren&rsquo;t always compatible with definitions in the legal system.">
<meta itemprop="datePublished" content="2021-01-07T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2021-01-07T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="926">



<meta itemprop="keywords" content="reading club,neurips," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Paper] On the Legal Compatibility of Fairness Definitions"/>
<meta name="twitter:description" content="Fairness in machine learning is typically concerned with ideas like discrimination, disparate impact or treatment, or protected classes. This paper describes how the definitions being used in ML aren&rsquo;t always compatible with definitions in the legal system."/>
</head>
</head>



<body class="h-full flex flex-col justify-between" itemscope itemtype="http://schema.org/WebPage"><header class="bg-green-500" itemscope itemtype="http://schema.org/WPHeader">
  <div class="flex max-w-8xl container mx-auto">
    <div class="hidden sm:inline flex items-center">
      <a href="/">
        <img class="rounded-full m-1 md:m-4" src="/headshot.jpg" width="100" height="100">
      </a>
    </div>
    <div class="w-full px-4 flex flex-col lg:flex-row justify-start md:pt-4 lg:items-center my-4">
      <div class="lg:flex-grow">
        <a href="/">
          <span class="text-lg sm:text-2xl md:text-3xl font-semibold">Tushar Chandra</span>
          <span class="hidden pl-4 lg:inline"><br></span>
          <span class="text-sm md:text-xl font-thin pl-4 md:pl-8 lg:pl-0 lg:text-xl">Data Scientist / Chicago, IL
          </span>
        </a>
      </div>
      <nav class="" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="flex lg:justify-between">
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/about">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-mug-hot"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">About</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/resume">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-file"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Resume</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/reading">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-book-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Reading</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/categories.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-folder-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Categories</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/posts.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-archive"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Archives</span>
              </a>
            </p>
          </li>

        </ul>

      </nav>
    </div>

  </div>
</header>
  <div class="container mx-auto max-w-8xl px-4 flex flex-row flex-grow">
    <div class="w-full md:w-3/4">
      
<main class="main" role="main"><div class="content container mx-auto max-w-6xl">
  <article id="-" class="" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="pt-4">
      <span class="font-semibold text-3xl"><h1 itemprop="name">
  <a class="" href="/papers/legal_compatibility_fairness_definitions_xiang.html">[Paper] On the Legal Compatibility of Fairness Definitions</a>
</h1>
      </span>
      <div class="pb-4"><i class="fas fa-calendar-check text-gray-500 pr-1"></i>
<time datetime="2021-01-07 00:00:00 &#43;0000 UTC" class="text-sm text-gray-600"
  itemprop="datePublished">2021-01-07</time>
<span class="text-sm text-gray-600" itemprop="wordCount">
	<i class="fas fa-pencil-alt text-gray-500 pl-4 pr-2"></i>926 words
</span><i class="fas fa-folder-open text-gray-500 pl-4 pr-1"></i>
<a class="text-sm text-gray-600" href=" /categories/papers.html"> papers, </a>
<span class="article-tag">
  <i class="fas fa-tag text-gray-500 pl-4 pr-1"></i>
  <a class="text-sm text-gray-600" href="/tags/reading-club.html"> reading club, </a>
  <a class="text-sm text-gray-600" href="/tags/neurips.html"> neurips, </a>
</span><span class="article-category text-sm text-gray-600 pl-4">
  <i class="fa fa-users "></i>
  Alice Xiang, Inioluwa Deborah Raji
</span>
      </div>
    </div>
    <div class="rich-text" itemprop="articleBody">
      <p>Fairness in machine learning is typically concerned with ideas like discrimination, disparate impact or treatment, or protected classes. This paper describes how the definitions being used in ML aren&rsquo;t always compatible with definitions in the legal system.</p>
<p><strong>Links</strong>: <a href="https://arxiv.org/abs/1912.00761">arXiv</a>, <a href="https://www.partnershiponai.org/to-prevent-algorithmic-bias-legal-and-technical-definitions-around-algorithmic-fairness-must-align/">blog post</a>, <a href="https://twitter.com/rajiinio/status/1201694932215517185">Twitter thread</a>; presented at the HCML workshop at NeurIPS 2019</p>
<h2 id="background-and-motivation"><a class="not-rich" href="#background-and-motivation"><i class="fas fa-link"></i></a> Background and motivation</h2>
<p>The machine learning community and legal system do not always agree on definitions of fairness. The ML fairness community will use legal terminology in imprecise or misleading ways. This is problematic for two reasons:</p>
<blockquote>
<p>First, to demonstrate evidence of algorithmic unfairness, ML definitions must accurately map onto their legal counterparts to establish liability. &hellip; Second, to deploy bias correction methods in the real world, it is important that the methods themselves are not determined to be discriminatory from a legal perpsective.</p>
</blockquote>
<p>ML models must be compatible with the law. This means more than avoiding discrimination. It means that the language and metrics, or lack thereof, to avoid discrimination must match between the ML domain and the legal one.</p>
<h2 id="examples-of-poorly-mapped-concepts"><a class="not-rich" href="#examples-of-poorly-mapped-concepts"><i class="fas fa-link"></i></a> Examples of poorly mapped concepts</h2>
<p>The authors described a few concepts that are imprecisely mapped between the ML fairness community and the legal definitions. This table is a summary of Section 2 in the paper.</p>
<table>
<thead>
<tr>
<th>Concept</th>
<th>ML interpretation</th>
<th>Legal interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Discrimination</td>
<td>Typically defined in terms of metrics, which can be &ldquo;removed&rdquo;</td>
<td>Typically defined through &ldquo;motive, evidenced intent of exclusion, and causality, rather than simply outcomes,&rdquo; which is gauged in context</td>
</tr>
<tr>
<td>Protected classes</td>
<td>Often conflated with &ldquo;minority and marginalized groups&rdquo;</td>
<td>Symmetric with respect to race and gender</td>
</tr>
<tr>
<td>Affirmative action</td>
<td>Treated as cases where we &ldquo;explicitly take demographics into account&rdquo;</td>
<td>Allows the use of race as a holistic, not explicit, factor</td>
</tr>
<tr>
<td>Disparate treatment</td>
<td>Whether a protected attribute is used in a decision process</td>
<td>Asks whether actions were <em>motivated</em> by discriminatory intent</td>
</tr>
<tr>
<td>Disparate impact</td>
<td>&ldquo;when outcomes differ across subgroups&rdquo;</td>
<td>Only shown if the outcomes can&rsquo;t be explained in a nondiscriminatory manner, or if there is no less discriminatory alternative</td>
</tr>
</tbody>
</table>
<p>The discrimination example stood out to me. The authors cite <a href="/papers/equality_of_opportunity_srebro.html">Equality of Opportunity in Supervised Learning</a> as an example of something you <em>can&rsquo;t</em> do—&ldquo;remove discrimination&rdquo;—which I didn&rsquo;t think about when reading that a few months ago.</p>
<p>It&rsquo;s also worth noting that the legal community might adopt narrower views of court decisions than the ML fairness community. When cases are heavily motivated by the details (in an example about disparate treatment in promoting firefighters, &ldquo;the fact that many firefighters spent significant time and money preparing for the test&rdquo;), it may not be possible to draw broad conclusions about its applicability.</p>
<h2 id="lessons-for-ml-fairness"><a class="not-rich" href="#lessons-for-ml-fairness"><i class="fas fa-link"></i></a> Lessons for ML fairness</h2>
<p><strong>Intersectionality</strong> (the idea that people&rsquo;s identities interact, e.g., that Black women face challenges different than the union of challenges faced by Black people and by women) is typically not considered in ML fairness, where people are represented as vectors of their class attribiutes.</p>
<p><strong>Procedural fairness</strong> in ML typically refers to the features that help a model make its decision. Legally, it is a qualitative concept that &ldquo;seeks to arrive at just outcomes through iterative processes and the close examination of the set of governance structures in place to guide individual human decision-making.&rdquo; Far broader and fuzzier than anything seen in ML, where <a href="/papers/reliance_metrics_problem_thomas.html">metrics rule all</a>.</p>
<h2 id="lessons-for-law"><a class="not-rich" href="#lessons-for-law"><i class="fas fa-link"></i></a> Lessons for law</h2>
<p>On the other hand, <strong>measuring bias</strong> becomes empirically possible with algorithms. &ldquo;Making a case for the use of protected variables to effectively measure discrimination, although an intuitive and proven conclusion from a mathematical perspective, is still much more difficult to make a case for in a legal sense.&rdquo; The legal system could adapt to the emergent reality of algorithms here.</p>
<p>The law also typically requires <strong>narrower domains</strong> for anti-discrimination protections than the fairness community is accustomed to, and the ML community could feasibly inform what the future should look like:</p>
<blockquote>
<p>Although ML research often discusses the fairness of ad targeting and recommendation algorithms, bias in these algorithms—although potentially immoral-is not generally illegal.</p>
</blockquote>
<p>I&rsquo;m thinking here about Twitter&rsquo;s <a href="https://www.theverge.com/2020/10/2/21498619/twitter-image-cropping-update-racial-bias-machine-learning">image cropping algorithm</a>, which was found to favor images of white people over Black ones. It&rsquo;s not illegal that it was biased in this way, and it&rsquo;s hard to imagine that it should be. But were this to somehow cause someone harm, it would be hard to find legal recourse.</p>
<p>Finally, anti-discrimination laws are often motivated by <strong>causality</strong>, but algorithmic causality is murkier. &ldquo;From a statistical perpsective, the presence or absence of protected class variables (or close proxies) in the algorithm does not indicate the presence or absense of a causal connection.&rdquo; The ML community might need to intermediate between legal and statistical definitions of causality.</p>
<h2 id="my-thoughts"><a class="not-rich" href="#my-thoughts"><i class="fas fa-link"></i></a> My thoughts</h2>
<p>This is an interesting paper! I wonder how prescient it&rsquo;ll end up seeming. It feels to me like relevant case law is either sparse or doesn&rsquo;t yet exist; that we&rsquo;re still awaiting court decisions to clarify on how discrimination in ML will end up being mapped onto our legal system.</p>
<p>The idea reminds me of <em>construct validity</em> in social computing—that whatever definitions of fairness we come up with have to be compatible with their legal counterparts. It makes sense; especially if ML uses a subtley different definition, that could just end up confusing courts.</p>
<p>A little over a year ago, I read <a href="/papers/discrimination_algorithms_kleinberg_1.html">Discrimination in the Age of Algorithms</a>, which talked about how definitions of and regulations for discrimination will have to evolve over time. They too analyze issues of disparate impact and treatment, bias, and affirmative action to see how they might be reimagined in a future with more algorithmic decisions.</p>
<p>I&rsquo;m looking forward to seeing how this issue evolves over time.</p>

      <p><i class="fas fa-square font-green-800"></i></p>
    </div>
    <div class="font-semibold text-green-800 pt-4">
      <a href="/"><i class="fas fa-arrow-left"></i> Return home</a>
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/posts/year_in_review_2020.html" title="My 2020 in Review"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;</span></a>
            </li>
            <li class="next">
                <a href="/what_i_read/20210109.html"
                    title="What I read this week (January 3 - 9)"><span>&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>

</main>
    </div>
    <div class="hidden w-0 md:block md:w-1/4 md:pt-8 md:pl-12"><aside class="" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="pb-8">
    <h3 class="font-semibold text-xl">Categories</h3>
    <ul class="">
        <li class="">+ <a href="/categories/books.html" class="font-bold text-green-900">books
            </a><span class="">25</span>
        </li>
        <li class="">+ <a href="/categories/general.html" class="font-bold text-green-900">general
            </a><span class="">44</span>
        </li>
        <li class="">+ <a href="/categories/papers.html" class="font-bold text-green-900">papers
            </a><span class="">94</span>
        </li>
        <li class="">+ <a href="/categories/projects.html" class="font-bold text-green-900">projects
            </a><span class="">7</span>
        </li>
        <li class="">+ <a href="/categories/self.html" class="font-bold text-green-900">self
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/categories/spark.html" class="font-bold text-green-900">spark
            </a><span class="">34</span>
        </li>
        <li class="">+ <a href="/categories/what-i-read.html" class="font-bold text-green-900">what-i-read
            </a><span class="">53</span>
        </li>
    </ul>
</div>
<div class="pb-4">
    <h3 class="font-semibold text-xl">Recent Posts</h3>
    <ul class="recent-post-list list-unstyled no-thumbnail">
        <li class="pb-4">
            <p>
                <a href="/papers/primer_in_bertology_rogers.html" class="font-bold text-green-900">[Paper] A Primer in BERTology: What We Know About How BERT Works</a>
                <time datetime="2021-03-25 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2021-03-25
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/formalizing_trust_ai_goldberg.html" class="font-bold text-green-900">[Paper] Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI</a>
                <time datetime="2021-03-11 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2021-03-11
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/we_are_dynamo_salehi.html" class="font-bold text-green-900">[Paper] We Are Dynamo: Overcoming Stalling and Friction in Collective Action for Crowd Workers</a>
                <time datetime="2021-03-04 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2021-03-04
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/datasheets_for_datasets.html" class="font-bold text-green-900">[Paper] Datasheets for Datasets</a>
                <time datetime="2021-02-25 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2021-02-25
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/stochastic_parrots_bender.html" class="font-bold text-green-900">[Paper] On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜</a>
                <time datetime="2021-02-11 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2021-02-11
                </time>
            </p>

        </li>
    </ul>
</div><div class="pb-12">
    <h3 class="font-semibold text-xl">Tags</h3>
    <ul class="">
        <li class="">+ <a href="/tags/#republic.html" class="font-bold text-green-900">#republic
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/chi.html" class="font-bold text-green-900">chi
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/chi2019.html" class="font-bold text-green-900">chi2019
            </a><span class="">3</span>
        </li>
        <li class="">+ <a href="/tags/chi2020.html" class="font-bold text-green-900">chi2020
            </a><span class="">20</span>
        </li>
        <li class="">+ <a href="/tags/chi2021.html" class="font-bold text-green-900">chi2021
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/cscw2020.html" class="font-bold text-green-900">cscw2020
            </a><span class="">8</span>
        </li>
        <li class="">+ <a href="/tags/facct2021.html" class="font-bold text-green-900">facct2021
            </a><span class="">3</span>
        </li>
        <li class="">+ <a href="/tags/fat2020.html" class="font-bold text-green-900">fat2020
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/iclr.html" class="font-bold text-green-900">iclr
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/icwsm2020.html" class="font-bold text-green-900">icwsm2020
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/indistractable.html" class="font-bold text-green-900">indistractable
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/neurips.html" class="font-bold text-green-900">neurips
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/password-tool.html" class="font-bold text-green-900">password-tool
            </a><span class="">6</span>
        </li>
        <li class="">+ <a href="/tags/reading-club.html" class="font-bold text-green-900">reading-club
            </a><span class="">28</span>
        </li>
        <li class="">+ <a href="/tags/recsys.html" class="font-bold text-green-900">recsys
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/site.html" class="font-bold text-green-900">site
            </a><span class="">6</span>
        </li>
        <li class="">+ <a href="/tags/www.html" class="font-bold text-green-900">www
            </a><span class="">3</span>
        </li>
    </ul>
</div>
</aside><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
  <div class="mx-auto mt-auto w-full px-4 bg-green-500 mt-4 md:py-8">
    <div class="md:invisible md:hidden max-w-8xl"><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>







<script data-goatcounter="https://tusharc.goatcounter.com/count" async src="//gc.zgo.at/count.js">
</script>
</body>

</html>