<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <title>
        Paper: Discrimination in the Age of Algorithms (2/2) - Tushar Chandra
      </title>
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" />
  
  <meta name="description" content="Part 2 of the summary of the paper by Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein, published in the Journal of Legal Analysis. View part 1 here.
" />
  <meta name="generator" content="Hugo 0.62.0 with theme pure" />
  <title>Paper: Discrimination in the Age of Algorithms (2/2) - Tushar Chandra</title>
  

  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
  <meta property="og:title" content="Paper: Discrimination in the Age of Algorithms (2/2)" />
<meta property="og:description" content="Part 2 of the summary of the paper by Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein, published in the Journal of Legal Analysis. View part 1 here." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/papers/discrimination_algorithms_kleinberg_2.html" />
<meta property="article:published_time" content="2019-12-30T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-12-30T00:00:00+00:00" />
<meta itemprop="name" content="Paper: Discrimination in the Age of Algorithms (2/2)">
<meta itemprop="description" content="Part 2 of the summary of the paper by Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein, published in the Journal of Legal Analysis. View part 1 here.">
<meta itemprop="datePublished" content="2019-12-30T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-12-30T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1087">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Paper: Discrimination in the Age of Algorithms (2/2)"/>
<meta name="twitter:description" content="Part 2 of the summary of the paper by Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein, published in the Journal of Legal Analysis. View part 1 here."/>
</head>
  </head>
  

  <body class="main-center theme-blue" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader">
    <div class="slimContent">
      <div class="navbar-header">
        <div class="profile-block text-center">
          <a id="avatar">
            <img class="img-circle" src="/headshot.jpg" width="300" height="300">
          </a>
          <h2 id="name" class="hidden-xs hidden-sm"><b>Tushar Chandra</b></h2>
          <h3 id="title" class="hidden-xs hidden-sm hidden-md">Data Scientist</h3>
          <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Chicago, IL</small>
        </div>
      </div>
      <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="nav navbar-nav main-nav">
            <li class="menu-item menu-item-home">
                <a href="/">
                    <i class="icon icon-home-fill"></i>
                  <span class="menu-title">Home</span>
                </a>
            </li>
            <li class="menu-item menu-item-about">
                <a href="/about">
                    <i class="icon icon-cup-fill"></i>
                  <span class="menu-title">About</span>
                </a>
            </li>
            <li class="menu-item menu-item-resume">
                <a href="/resume">
                    <i class="icon icon-file"></i>
                  <span class="menu-title">Resume</span>
                </a>
            </li>
            <li class="menu-item menu-item-categories">
                <a href="/categories.html">
                    <i class="icon icon-folder"></i>
                  <span class="menu-title">Categories</span>
                </a>
            </li>
            <li class="menu-item menu-item-archives">
                <a href="/posts.html">
                    <i class="icon icon-archives-fill"></i>
                  <span class="menu-title">Archives</span>
                </a>
            </li>
        </ul>
      </nav>
    </div>
  </header>

<aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <div class="widget">
    <h3 class="widget-title"> Categories</h3>
    <div class="widget-body">
        <ul class="category-list">
            <li class="category-list-item"><a href="/categories/about.html" class="category-list-link">about</a><span class="category-list-count">2</span></li>
            <li class="category-list-item"><a href="/categories/general.html" class="category-list-link">general</a><span class="category-list-count">13</span></li>
            <li class="category-list-item"><a href="/categories/papers.html" class="category-list-link">papers</a><span class="category-list-count">11</span></li>
            <li class="category-list-item"><a href="/categories/spark.html" class="category-list-link">spark</a><span class="category-list-count">13</span></li>
            <li class="category-list-item"><a href="/categories/what-i-read.html" class="category-list-link">what-i-read</a><span class="category-list-count">4</span></li>
        </ul>
    </div>
</div>
<div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
        <ul class="recent-post-list list-unstyled no-thumbnail">
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/discrimination_algorithms_kleinberg_2.html" class="title">Paper: Discrimination in the Age of Algorithms (2/2)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2019-12-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-30</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/papers/discrimination_algorithms_kleinberg_1.html" class="title">Paper: Discrimination in the Age of Algorithms (1/2)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2019-12-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-29</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/posts/talk_aguera_neurips.html" class="title">Blaise Aguera y Arcas: Social Intelligence (NeurIPS 2019)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2019-12-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-28</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/what_i_read/20191228.html" class="title">What I read this week (December 22 - 28)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2019-12-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-28</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/posts/talk_kidd_neurips.html" class="title">Celeste Kidd: How to Know (NeurIPS 2019)</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2019-12-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-27</time>
                    </p>
                </div>
            </li>
        </ul>
    </div>
</div>
  </div>
</aside>

    
    
<main class="main" role="main"><div class="content">
  <article id="-" class="article article-type-" itemscope
    itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      <h1 itemprop="name">
  <a
    class="article-title"
    href="/papers/discrimination_algorithms_kleinberg_2.html"
    >Paper: Discrimination in the Age of Algorithms (2/2)</a
  >
</h1>

      <div class="article-meta">
        <span class="article-date">
  <i class="icon icon-calendar-check"></i>
<a href="/papers/discrimination_algorithms_kleinberg_2.html" class="article-date">
  <time datetime="2019-12-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">2019-12-30</time>
</a>
</span><span class="article-category">
  <i class="icon icon-folder"></i>
  <a class="article-category-link" href="/categories/papers.html"> papers </a>
</span>

        
      </div>
    </div>
    <div class="article-entry marked-body js-toc-content" itemprop="articleBody">
      <p>Part 2 of the summary of the paper by Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein, published in the <a href="https://academic.oup.com/jla/article/doi/10.1093/jla/laz001/5476086">Journal of Legal Analysis</a>. View part 1 <a href="/papers/discrimination_algorithms_kleinberg_1.html">here</a>.</p>
<h2 id="regulation-of-algorithms">Regulation of algorithms</h2>
<p>Regulation of algorithms, the authors posit, requires us to be able to understand human choices on (1) the outcome to predict, (2) the inputs available to the algorithm for consideration, and (3) the training procedure used. Transparency is therefore necessary to the process; fortunately, the use of algorithms makes it more feasible and productive compared to human decision making. It's unclear what kinds of record keeping requirements would need to be passed, and the authors make several suggestions.</p>
<p>The authors claim early on, then prove in the Appendix, that algorithmic bias can be completely decomposed into bias from those three factors (the choice of outcome, the choice of input variables, and the design of the training procedure). Once those are accounted for, what remains is the structural disadvantage between groups. That's an interesting claim that I haven't been able to totally wrap my head around, and it certainly merits further thought.</p>
<blockquote>
<p>Our central claim &hellip; is that safeguards against the biases of people who build algorithms, rather than against algorithms per se, could play a key role in ensuring that algorithms are not being built in a way that discriminates &hellip; If we do that, then algorithms go beyond merely being a threat to be regulated; they can also be a positive force for social justice.</p>
</blockquote>
<h2 id="algorithms-for-equity">Algorithms for equity</h2>
<p>&ldquo;Algorithms have the potential to help us to excise disparate treatment,&rdquo; the authors write, and &ldquo;to reduce discrimination relative to human decision-making,&rdquo; which they call &ldquo;disparate benefit&rdquo; of algorithms. They discuss how algorithms have no hidden agendas; any agendas they have must be specified in code. They mention that, in contrast to humans, access to protected variables <em>promotes</em> equity for a properly designed algorithm can promote equity.</p>
<p>The authors consider a controversial example of two college applicants who scored 1100 on the SAT: one who went to school at New Trier and one who went to school in Englewood. Barring extraordinary circumstances, the authors write, &ldquo;it <em>cannot</em> be the case that the amount of effort, persistence, and extra learning on one's own required to score 1100 on the SAT is the same for the student who starts with every possible advantage as for the one forced to overcome a long list of difficult obstacles.&rdquo; Yet a race-blind (and perhaps neighborhood-blind, economic-circumstances-blind, and other-proxies-for-race-blind) algorithm is <em>precisely</em> forced to assume that this is the case. They create a mathematical model of this to further demonstrate the point.</p>
<p>Yet another point is that equity improvements may come simply from algorithms being better predictors than humans. Better prediction in tenant risk assessments might allow landlords to relax collateral requirements. Better prediction of missed payment risk might allow lenders to lower interest rates for families who would otherwise have unmanageably high ones. More generally, shrinking systems that otherwise disproportionately harm disadvantaged groups is a major possible outcome of algorithmic decision making.</p>
<p>One final potential benefit is that algorithms can help reveal our own biases. If a hiring algorithm trained on past applicant data ends up hiring mostly men, then an evaluation of this algorithm would reveal biased past behavior. This is likely what happened when Amazon tried to do this.</p>
<h2 id="thoughts-connections-and-questions">Thoughts, connections, and questions</h2>
<p>A great quote from the introduction:</p>
<blockquote>
<p>Algorithms do not build themselves. The Achilles&rsquo; heel of all algorithms is the humans who build them and the choices they make about outcomes, candidate predictors for the algorithm to consider, and the training sample. A critical element of regulating algorithms is regulating humans.</p>
</blockquote>
<p>I love this idea. Regulating algorithms independently of the humans that develop them is bound to fail; this is how we end up with senseless blanket bans on technologies or tedious lists of what we can and can't do. I'm influenced by Patrick Hall <a href="/spark/interpretable_ai.html">discussing</a> how if we (as ML researchers and practitioners) don't learn to regulate ourselves, then the government will likely do so in a draconian fashion. While the suggestions made in this paper are all taken from a legal perspective, perhaps a company could choose to keep this kind of documentation on their own as they build models. This is complementary to <a href="/papers/model_cards_mitchell.html">model cards</a>, I think, which IMO focuses more on documentation of a finished model and not of the model buliding process.</p>
<p>The discussion of access to protected variables being able to increase equity is counterintuitive, but seems to make sense. A properly designed algorithm would be able to take those into account. This reminds me of hierarchical models, where you can specify group-level predictors and learn different coefficients for those explicitly. Accounting for these explicitly in a model might allow one to later negate them by &ldquo;flipping&rdquo; the value of that predictor (white to black, female to male, etc.), and to understand the impact of that predictor by looking at (in a linear model) the coefficients.</p>
<p>I think a likely underappreciated point (well, I have no idea how much anyone appreciates any point in this paper) is the importance of choosing the right objective function. <a href="/posts/talk_kidd_neurips.html">Aguera discussed</a> how few problems can be specified in terms of a loss function, and the authors here make clear that the choice of this objective is one of the keys to understanding discrimination in algorithms. A related problem, then, is how we <em>develop</em> these objectives for complex problems that don't have any sort of mathematical formulation, and how we do so in a legal and fair way.</p>
<p>Another question (which I haven't thought too much about) is the extent to which this process deals with &ldquo;black box&rdquo; algorithms. I suppose that given any training procedure, the objective must be clear (and this paper mandates that it must be documented), and the possible features are readily available. The output of the trainer (the &ldquo;screener&rdquo;) is easy to evaluate by passing arbitrary inputs through it in order to see how it responds, and if necessary one could take a linear approximation to an otherwise black-box screener.</p>
<p>This paper was great. Reading 40+ pages was challenging, but it was a really interesting read. Seeing the connection between algorithmic bias and the existing legal framework around discrimination was a unique read; to date, I haven't seen any treatment as in-depth as this one. Kleinberg and the other authors did an excellent job at making both complex legal concepts and complex CS concepts accessible to people of either background.</p>
    </div>
    <div class="article-footer">
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/papers/discrimination_algorithms_kleinberg_1.html" title="Paper: Discrimination in the Age of Algorithms (1/2)"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;Older</span></a>
            </li>
            <li class="next">
                <a href="/resume/"
                    title="Resume"><span>Newer&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>


</main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
<ul class="social-links">
    <li><a href="https://github.com/tuchandra" target="_blank" title="github" data-toggle=tooltip data-placement=top >
            <i class="icon icon-github"></i></a></li>
    <li><a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin" data-toggle=tooltip data-placement=top >
            <i class="icon icon-linkedin"></i></a></li>
    <li><a href="/index.xml" target="_blank" title="rss" data-toggle=tooltip data-placement=top >
            <i class="icon icon-rss"></i></a></li>
</ul>
  <div class="copyright">
    &copy; 2019 - 2020 Tushar Chandra
    <div class="publishby">
        Theme: <a href="https://github.com/xiaoheiAh/hugo-theme-pure" target="_blank">Hugo Pure</a>.
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js"></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>

  </body>
</html>
