<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <title>
    [Paper] Discrimination in the Age of Algorithms (1/2) - Tushar Chandra
    </title>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  <meta http-equiv="window-target" content="_top" /><meta name="description" content="How do algorithms affect discrimination, in the legal sense of the word? Naively, one might say that algorithms must be regulated and heavily scrutinized to avoid computers encoding human biases. This paper studies not only that, but also the opposite idea: that they can be positive forces for good. (Part 1 of 2.)
" />
  <meta name="generator" content="Hugo 0.70.0" />
  <title>[Paper] Discrimination in the Age of Algorithms (1/2) - Tushar Chandra</title>

  
  
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">

  <meta property="og:title" content="[Paper] Discrimination in the Age of Algorithms (1/2)" />
<meta property="og:description" content="How do algorithms affect discrimination, in the legal sense of the word? Naively, one might say that algorithms must be regulated and heavily scrutinized to avoid computers encoding human biases. This paper studies not only that, but also the opposite idea: that they can be positive forces for good. (Part 1 of 2.)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/papers/discrimination_algorithms_kleinberg_1.html" />
<meta property="article:published_time" content="2019-12-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-12-29T00:00:00+00:00" />
<meta itemprop="name" content="[Paper] Discrimination in the Age of Algorithms (1/2)">
<meta itemprop="description" content="How do algorithms affect discrimination, in the legal sense of the word? Naively, one might say that algorithms must be regulated and heavily scrutinized to avoid computers encoding human biases. This paper studies not only that, but also the opposite idea: that they can be positive forces for good. (Part 1 of 2.)">
<meta itemprop="datePublished" content="2019-12-29T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-12-29T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1181">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Paper] Discrimination in the Age of Algorithms (1/2)"/>
<meta name="twitter:description" content="How do algorithms affect discrimination, in the legal sense of the word? Naively, one might say that algorithms must be regulated and heavily scrutinized to avoid computers encoding human biases. This paper studies not only that, but also the opposite idea: that they can be positive forces for good. (Part 1 of 2.)"/>
</head>
</head>



<body class="h-full flex flex-col justify-between" itemscope itemtype="http://schema.org/WebPage"><header class="w-screen bg-green-500" itemscope itemtype="http://schema.org/WPHeader">
  <div class="flex max-w-8xl container mx-auto">
    <div class="hidden sm:inline flex items-center">
      <a href="/">
        <img class="rounded-full m-1 md:m-4" src="/headshot.jpg" width="100" height="100">
      </a>
    </div>
    <div class="w-full px-4 flex flex-col lg:flex-row justify-start md:pt-4 lg:items-center my-4">
      <div class="xl:flex-grow">
        <a href="/">
          <span class="text-lg sm:text-2xl md:text-3xl font-semibold">Tushar Chandra</span>
          <span class="hidden pl-4 lg:inline"><br></span>
          <span class="text-sm md:text-xl font-thin pl-4 md:pl-8 lg:pl-0 lg:text-xl">Data Scientist / Chicago, IL
          </span>
        </a>
      </div>
      <nav class="" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="flex lg:justify-between">
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/about">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-mug-hot"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">About</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/resume">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-file"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Resume</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/reading">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-book-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Reading</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/categories.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-folder-open"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Categories</span>
              </a>
            </p>
          </li>
          <li class="flex-grow-0 inline pr-1 md:pr-2 xl:px-4">
            <p class="text-center">
              <a href="/posts.html">
                <i class="fas text-green-800 pl-1 md:px-1 text-sm md:text-xl lg:text-2xl fa-archive"></i>
                <span class="font-thin text-sm md:text-lg lg:text-2xl">Archives</span>
              </a>
            </p>
          </li>

        </ul>

      </nav>
    </div>

  </div>
</header>
  <div class="container mx-auto max-w-8xl px-4 flex flex-row flex-grow">
    <div class="w-full md:w-3/4">
      
<main class="main" role="main"><div class="content container mx-auto max-w-6xl">
  <article id="-" class="" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="pt-4">
      <span class="font-semibold text-3xl"><h1 itemprop="name">
  <a class="" href="/papers/discrimination_algorithms_kleinberg_1.html">[Paper] Discrimination in the Age of Algorithms (1/2)</a>
</h1>
      </span>
      <div class="pb-4"><i class="fas fa-calendar-check text-gray-500 pr-1"></i>
<time datetime="2019-12-29 00:00:00 &#43;0000 UTC" class="text-sm text-gray-600"
  itemprop="datePublished">2019-12-29</time>
<span class="text-sm text-gray-600" itemprop="wordCount">
	<i class="fas fa-pencil-alt text-gray-500 pl-4 pr-2"></i>1181 words
</span><i class="fas fa-folder-open text-gray-500 pl-4 pr-1"></i>
<a class="text-sm text-gray-600" href=" /categories/papers.html"> papers, </a><span class="article-category text-sm text-gray-600 pl-4">
  <i class="fa fa-users "></i>
  Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, Cass R Sunstein
</span>
      </div>
    </div>
    <div class="rich-text" itemprop="articleBody">
      <p>How do algorithms affect discrimination, in the legal sense of the word? Naively, one might say that algorithms must be regulated and heavily scrutinized to avoid computers encoding human biases. This paper studies not only that, but also the opposite idea: that they can be positive forces for good. (Part 1 of 2.)</p>
<p><strong>Authors</strong>: Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Cass R Sunstein</p>
<p><strong>Link</strong>: in the <a href="https://academic.oup.com/jla/article/doi/10.1093/jla/laz001/5476086">Journal of Legal Analysis</a> (yeah, a law journal, we&rsquo;ll see how reading this goes).</p>
<p><strong>How I found this paper:</strong> from the NYT article, <a href="https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html">biased algorithms are easier to fix than biased people</a>.</p>
<p>This is part 1/2, because of how long this paper is; view part 2 <a href="/papers/discrimination_algorithms_kleinberg_2.html">here</a>.</p>
<h2 id="summary"><a class="not-rich" href="#summary"><i class="fas fa-link"></i></a> Summary</h2>
<p>From the abstract (bolded emphasis mine):</p>
<blockquote>
<p>To understand how algorithms affect discrimination, we must understand how they affect the <em>detection</em> of discrimination. With the appropriate requirements in place, algorithms create the potential for new forms of transparency and hence opportunities to detect discrimination that are otherwise unavailable. The specificity of algorithms also makes transparent tradeoffs among competing values. This implies <strong>algorithms are not only a threat to be regulated; with the right safeguards, they can be a potential positive force for equity.</strong></p>
</blockquote>
<p>The central claim of the paper is that &ldquo;when algorithms are involved, proving discrimination will be easierâ€”or at least it should be, and can be made to be.&rdquo; Regulating the design of algorithms with detailed record-keeping requirements, the authors claim, could provide transparency about the decisions being made. Opaque algorithms do not prevent regulators from studying their construction or behavior, which are both impossible with humans. Crucially, though, this requires that all components of the algorithm be stored, including training data.</p>
<p>The authors state that &ldquo;a well-regulated process involving algorithms stands out for its <em>transparency</em> and <em>specificity</em>&quot;, in contrast to humans who often do not know why they make the decisions that they do. In other words, answering the questions &ldquo;on what basis are they choosing&rdquo; and &ldquo;why did they pick those factors&rdquo;â€”two important questions when evaluating humans for discriminationâ€”are much more feasible with algorithms. The authors make clear that &ldquo;algorithmic&rdquo; does not mean &ldquo;objective,&rdquo; and to conflate the two is dangerous.</p>
<p>Consider a hypothetical, summarized from the paper: a company is accused of gender discrimination in hiring. A plaintiff argues that they have more education than male candidates who were hired, but the company argues that they value work experience as well, of which the plaintiff has less. The plaintiff argues that work experience is cited after the fact &hellip; this goes back and forth, and the point is that it&rsquo;s difficult to know whether or not the company has discriminated based on gender. But &ldquo;in a well-regulated world with algorithms,&rdquo; one could ask for the screening and training algorithms and the training data, experts could use counterfactuals to statistically evaluate how different applicants are treated, and look for signs of disparate impact.</p>
<h2 id="five-critical-points"><a class="not-rich" href="#five-critical-points"><i class="fas fa-link"></i></a> Five critical points</h2>
<p>The authors make five points, which they develop in detail throughout the paper. I summarize them here.</p>
<p><strong>1:</strong> &ldquo;The challenge of regulating discrimination is fundamentally one of attribution&rdquo;: that is, when we observe disparity for a particular group, how do we explain that gap? It could be because the algorithm explicitly takes into account gender. It could be because of average differences in the training data. It could be because there&rsquo;s a proxy for race in a feature.</p>
<p><strong>2</strong>: &ldquo;This decomposition becomes easier once an algorithm is in the decision loop.&rdquo; The decisions studied become more specific than why an algorithm decided X; they now include why a particular objective was used (minimize MSE, predict salespeople with the highest revenue, maximize tenure at a company, etc.). This knowledge increases the amount of scrutiny that can be given to these decisions.</p>
<p><strong>3</strong>: &ldquo;If we regulate the human choices well, we might be willing to be more permissive towards how the algorithm uses information about personal attributes in certain ways.&rdquo; In some cases, the best way to mitigate the impact of biased data is to incorporate that data into algorithms, so that they can correct for these factors. This point was less clear to me.</p>
<p><strong>4</strong>: &ldquo;Algorithms will force us to make more explicit judgments about underlying principles.&rdquo; If there is a tradeoff between the desires to admit more minority students into a college and to maximize first year GPAs, the algorithms can quantify this tradeoff, and decision makers and regulators can decide what tradeoffs are acceptable.</p>
<p><strong>5</strong>: &ldquo;If appropriate regulation can protect against malfeasance in their deployment, then algorithms can become a potentially powerful force for good: they can dramatically reduce discrimination of multiple kinds.&rdquo; Implicit biases matter most inn an unstructured decision-making process; while algorithms will certainly have human biases in their e.g., objectives and data, they will reduce human bias present in an ambiguous decision process.</p>
<h2 id="summary-continued"><a class="not-rich" href="#summary-continued"><i class="fas fa-link"></i></a> Summary, continued</h2>
<p>The remainder of the 40+ page paper goes into detail about the legal ideas around discrimination (disparate treatment, disparate impact, and fair treatment), challenges with detecting discrimination (individual decisions being hard to explain, the inability to simulate counterfactuals, etc.), and other relevant legal perspectives surrounding these concepts.</p>
<p>The authors take care to discriminate between the <em>screener</em> (the algorithm that takes inputs and produces a decision) and the <em>trainer</em> (the algorithm that produces the screener). They argue that the distinction between the two is often overlooked, but important in practice. One common concern about algorithms &ldquo;doing literally anything&rdquo; can be assuaged when considering that the screener is constrained by the trainer, so given an appropriate trainer we need not worry about this.</p>
<p>The proposed framework is &ldquo;relevant to the situations where the training algorithm, screening algorithm, and training dataset are all fixed, stored objects that can be inspected.&rdquo; Importantly, this is not the case for e.g., online ad placement, where the algorithms used change rapidly and data flows in quickly. The authors are more concerned with &ldquo;micro-prediction&rdquo; tasks that typically affect an individual, like hiring.</p>
<p>The authors discuss where discrimination is and is not likely to arise in algorithmic decision making systems. It can easily arise in the choice of outcome, choice of features, and choice of training procedure (e.g., by using biased data, or more generally by using data that reflects past, biased, human decisions). It is unlikely to arise in choosing which features are used in the selection process (that happens statistically), in the screening algorithm (which is a mechanical result of a training algorithm given data, so discrimination in the screener must come from discrimination earlier in the pipeline), and by systematic differences across groups (which are not, by themselves, discriminatory in the legal sense).</p>
<p>They present four case studies of firms making hiring decisions then evaluate them from a legal perspective. Following that, they discuss how they would and would not be different given the use of algorithms to inform hiring. I don&rsquo;t have the legal background to make very many comments about this, but the theme appears to be that (when properly regulated and documented) there are different questions to be asked like what kinds of proof are necessary and what tradeoffs were made.</p>

      <p><i class="fas fa-square font-green-800"></i></p>
    </div>
    <div class="font-semibold text-green-800 pt-4">
      <a href="/"><i class="fas fa-arrow-left"></i> Return home</a>
    </div>
  </article>
</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="/posts/talk_aguera_neurips.html" title="Blaise Aguera y Arcas: Social Intelligence (NeurIPS 2019)"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;</span></a>
            </li>
            <li class="next">
                <a href="/papers/discrimination_algorithms_kleinberg_2.html"
                    title="[Paper] Discrimination in the Age of Algorithms (2/2)"><span>&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
        </ul>
    </div>
</nav>

</main>
    </div>
    <div class="hidden w-0 md:block md:w-1/4 md:pt-8 md:pl-12"><aside class="" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="pb-8">
    <h3 class="font-semibold text-xl">Categories</h3>
    <ul class="">
        <li class="">+ <a href="/categories/books.html" class="font-bold text-green-900">books
            </a><span class="">22</span>
        </li>
        <li class="">+ <a href="/categories/general.html" class="font-bold text-green-900">general
            </a><span class="">40</span>
        </li>
        <li class="">+ <a href="/categories/papers.html" class="font-bold text-green-900">papers
            </a><span class="">80</span>
        </li>
        <li class="">+ <a href="/categories/projects.html" class="font-bold text-green-900">projects
            </a><span class="">7</span>
        </li>
        <li class="">+ <a href="/categories/self.html" class="font-bold text-green-900">self
            </a><span class="">4</span>
        </li>
        <li class="">+ <a href="/categories/spark.html" class="font-bold text-green-900">spark
            </a><span class="">34</span>
        </li>
        <li class="">+ <a href="/categories/what-i-read.html" class="font-bold text-green-900">what-i-read
            </a><span class="">47</span>
        </li>
    </ul>
</div>
<div class="pb-4">
    <h3 class="font-semibold text-xl">Recent Posts</h3>
    <ul class="recent-post-list list-unstyled no-thumbnail">
        <li class="pb-4">
            <p>
                <a href="/books/hooked.html" class="font-bold text-green-900">My review of Nir Eyal&#39;s Hooked</a>
                <time datetime="2020-11-23 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-11-23
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/decolonial_ai_mohamed.html" class="font-bold text-green-900">[Paper] Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence</a>
                <time datetime="2020-11-20 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-11-20
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/complementary_nature_time_online_mok.html" class="font-bold text-green-900">[Paper] The Complementary Nature of Perceived and Actual Time Spent Online in Measuring Digital Well-being</a>
                <time datetime="2020-11-18 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-11-18
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/what_i_read/20201114.html" class="font-bold text-green-900">What I read this week (November 8 - 14)</a>
                <time datetime="2020-11-14 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-11-14
                </time>
            </p>

        </li>
        <li class="pb-4">
            <p>
                <a href="/papers/data_and_power_archival_schoenebeck.html" class="font-bold text-green-900">[Paper] Data and Power: Archival Appraisal Theory as a Framework for Data Preservation</a>
                <time datetime="2020-11-13 00:00:00 &#43;0000 UTC" itemprop="datePublished" class="text-gray-600 text-sm">2020-11-13
                </time>
            </p>

        </li>
    </ul>
</div><div class="pb-12">
    <h3 class="font-semibold text-xl">Tags</h3>
    <ul class="">
        <li class="">+ <a href="/tags/#republic.html" class="font-bold text-green-900">#republic
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/chi2019.html" class="font-bold text-green-900">chi2019
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/chi2020.html" class="font-bold text-green-900">chi2020
            </a><span class="">20</span>
        </li>
        <li class="">+ <a href="/tags/cscw2020.html" class="font-bold text-green-900">cscw2020
            </a><span class="">8</span>
        </li>
        <li class="">+ <a href="/tags/fat2020.html" class="font-bold text-green-900">fat2020
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/iclr.html" class="font-bold text-green-900">iclr
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/icwsm2020.html" class="font-bold text-green-900">icwsm2020
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/indistractable.html" class="font-bold text-green-900">indistractable
            </a><span class="">2</span>
        </li>
        <li class="">+ <a href="/tags/neurips.html" class="font-bold text-green-900">neurips
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/password-tool.html" class="font-bold text-green-900">password-tool
            </a><span class="">6</span>
        </li>
        <li class="">+ <a href="/tags/reading-club.html" class="font-bold text-green-900">reading-club
            </a><span class="">16</span>
        </li>
        <li class="">+ <a href="/tags/recsys.html" class="font-bold text-green-900">recsys
            </a><span class="">1</span>
        </li>
        <li class="">+ <a href="/tags/site.html" class="font-bold text-green-900">site
            </a><span class="">5</span>
        </li>
        <li class="">+ <a href="/tags/www.html" class="font-bold text-green-900">www
            </a><span class="">2</span>
        </li>
    </ul>
</div>
</aside><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
  <div class="mx-auto mt-auto w-screen px-4 bg-green-500 mt-4 md:py-8">
    <div class="md:invisible md:hidden max-w-8xl"><footer class="" itemscope itemtype="http://schema.org/WPFooter">
  <div class="py-4 text-sm">
    &copy; 2019 - 2020 Tushar Chandra
    <p style="margin-bottom: 4px">All opinions are my own.</p>
    <div class="publishby">Powered by Hugo with a custom theme.</div>
  </div>
  <ul class="">
    <li class="inline text-xl pr-4">
      <a href="https://github.com/tuchandra" target="_blank" title="github">
        <i class="fab fa-github"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="https://www.linkedin.com/in/tushar-chandra-76a623b6/" target="_blank" title="linkedin">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="mailto:me@tusharc.dev" target="_blank" title="envelope">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
    <li class="inline text-xl pr-4">
      <a href="/index.xml" target="_blank" title="rss">
        <i class="fas fa-rss"></i>
      </a>
    </li>

  </ul>
</footer>
    </div>
  </div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js"></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>


<script data-goatcounter="https://tusharc.goatcounter.com/count" async src="//gc.zgo.at/count.js">
</script>
</body>

</html>