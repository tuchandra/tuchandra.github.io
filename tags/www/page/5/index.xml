<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>www on Tushar Chandra</title>
    <link>/tags/www.html</link>
    <description>Recent content in www on Tushar Chandra</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/www/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>My review of &#39;You Look Like a Thing and I Love You&#39;</title>
      <link>/books/you_look_like_a_thing.html</link>
      <pubDate>Fri, 21 Aug 2020 20:00:00 +0000</pubDate>
      
      <guid>/books/you_look_like_a_thing.html</guid>
      <description>&lt;p&gt;I picked up &lt;a href=&#34;https://twitter.com/JanelleCShane&#34;&gt;Janelle Shane&amp;rsquo;s&lt;/a&gt; book, &lt;em&gt;You Look Like a Thing and I Love You&lt;/em&gt;, a couple of weeks ago. Combining clear explanations of AI with hilarious examples of how weird it can be, this was one of the best books I&amp;rsquo;ve read in a while.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Content moderation, AI, and the question of scale</title>
      <link>/papers/content_moderation_scale_gillespie.html</link>
      <pubDate>Fri, 21 Aug 2020 15:00:00 +0000</pubDate>
      
      <guid>/papers/content_moderation_scale_gillespie.html</guid>
      <description>&lt;p&gt;This short paper in &lt;em&gt;Big Data and Society&lt;/em&gt; came across my radar on Twitter today. Automated content moderation is often heralded as an answer to the impenetrable size of Facebook, YouTube, and other platforms. But it&amp;rsquo;s not clear that automation is the answer.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] The Media Coverage of the 2020 US Presidential Election Candidates through the Lens of Google&#39;s Top Stories</title>
      <link>/papers/media_coverage_presidential_google_kawakami.html</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/media_coverage_presidential_google_kawakami.html</guid>
      <description>&lt;p&gt;This is a &lt;em&gt;dataset paper&lt;/em&gt; from ICWSM 2020, presenting a dataset of nearly 80,000 news stories focusing on the 2020 US Presidential Election throughout 2019. It was shared to help researchers studying agenda setting and algorithmic curation of news.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Minor website addition: tags and anchors</title>
      <link>/posts/site_changes_tags.html</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/site_changes_tags.html</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve added tags to my site! You might notice that this post is tagged &amp;lsquo;site&amp;rsquo;, and some of the papers I read are tagged by conference. I also added anchors to make linking to sections easier.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Auditing News Curation Systems: A Case Study Examining Algorithmic and Editorial Logic in Apple News</title>
      <link>/papers/auditing_news_curation_systems_diakopoulos.html</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/auditing_news_curation_systems_diakopoulos.html</guid>
      <description>&lt;p&gt;Apple News is used by 85 million users daily, but what is it actually showing you? From what publishers do the stories come? How often are they updated? This ICWSM 2020 paper motivates and applies an algorithmic audit of the Apple News curation system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] What is AI Literacy? Competencies and Design Considerations</title>
      <link>/papers/what_is_ai_literacy_long.html</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/what_is_ai_literacy_long.html</guid>
      <description>&lt;p&gt;What does it mean to be AI literate? This work, which received a Best Paper Honorable Mention at CHI 2020, first defines &lt;em&gt;AI literacy&lt;/em&gt; in terms of its core competencies, then discusses considerations for the design of AI systems.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Personal news: I got promoted!</title>
      <link>/posts/promotion_senior.html</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/promotion_senior.html</guid>
      <description>&lt;p&gt;I was recently promoted to senior data scientist! This is a short post with some details and reflection.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>My review of &#39;Weapons of Math Destruction&#39;</title>
      <link>/books/weapons_math_destruction.html</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/books/weapons_math_destruction.html</guid>
      <description>&lt;p&gt;This is my review of &lt;em&gt;Weapons of Math Destruction&lt;/em&gt; by Dr. Cathy O&amp;rsquo;Neil. I found it to be a clearly written book, explaining many of the problems with &amp;ldquo;big data&amp;rdquo; systems: lack of access to proper data, problems that come from the scale of these systems, and vicious feedback loops.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (August 9 - 15)</title>
      <link>/what_i_read/20200815.html</link>
      <pubDate>Sat, 15 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200815.html</guid>
      <description>&lt;p&gt;I&amp;rsquo;m trying to put together my first submission for a conference CFP: &lt;a href=&#34;https://pymc-devs.github.io/pymcon//cfp&#34;&gt;PyMCon&lt;/a&gt;, an all-virtual conference happening this November. This week, I sought out a lot of blog posts about this to help.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Two Computational Models for Analyzing Political Attention in Social Media</title>
      <link>/papers/modeling_political_attention_hemphill.html</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/modeling_political_attention_hemphill.html</guid>
      <description>&lt;p&gt;What are members of Congress tweeting about, and how can we use machine learning to infer this? In this ICWSM 2020 paper, the researchers try out both supervised and unsupervised learning on all the tweets from members of the 115th Congress (Jan. 2017 - Jan. 2019).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Understanding deep learning requires rethinking generalization</title>
      <link>/papers/understanding_dl_generalization_zhang.html</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/understanding_dl_generalization_zhang.html</guid>
      <description>&lt;p&gt;This Google Brain paper from ICLR 2017 tackles the question of &lt;em&gt;generalization&lt;/em&gt; in neural networks. What causes a network that performs well on training data to also perform well on testing data? (Answer: ¯\_(ツ)_/¯)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (August 2 - 8)</title>
      <link>/what_i_read/20200808.html</link>
      <pubDate>Sat, 08 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200808.html</guid>
      <description>&lt;p&gt;A few articles from Pointer this week, an &lt;em&gt;amazing&lt;/em&gt; post titled &amp;ldquo;System Design for Advanced Beginners,&amp;rdquo; and some blogging advice.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] An Experimental Study of Structural Diversity in Social Networks</title>
      <link>/papers/experimental_study_structural_diversity_su.html</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/experimental_study_structural_diversity_su.html</guid>
      <description>&lt;p&gt;In a social network, structural diversity is a measure of how (dis)similar one&amp;rsquo;s social connections are. It&amp;rsquo;s positively correlated with engagement, but the mechanism behind this is unknown. This work experimentally alters structural diversity for new Twitter users, studying whether or not it affects user retention.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Local Trends in Global Music Streaming</title>
      <link>/papers/local_trends_streaming_way.html</link>
      <pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/local_trends_streaming_way.html</guid>
      <description>&lt;p&gt;Spotify makes a global music catalog available to subscribers around the world. Historically, that&amp;rsquo;s meant different countries have more access to each other&amp;rsquo;s music. How does that hold up in 5.5 years of Spotify streaming data?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 26 - August 1)</title>
      <link>/what_i_read/20200801.html</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200801.html</guid>
      <description>&lt;p&gt;This week&amp;rsquo;s articles include &amp;ldquo;Create space for others&amp;rdquo; by Will Larson, &amp;ldquo;What does sponsorship look like?&amp;rdquo; by Lara Hogan, and &amp;ldquo;Be Impatient&amp;rdquo; by Ben Kuhn.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] Generative Models for Effective ML on Private, Decentralized Datasets</title>
      <link>/papers/generative_models_augenstein.html</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/generative_models_augenstein.html</guid>
      <description>&lt;p&gt;How do you build and debug machine learning models when you don&amp;rsquo;t have access to the raw data? Maybe it&amp;rsquo;s sensitive information, or that it&amp;rsquo;s stored on user devices. This Google paper from ICLR 2020 proposes using &lt;em&gt;generative models&lt;/em&gt; as a privacy-preserving stand-in for user data.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What I read this week (July 19 - 25)</title>
      <link>/what_i_read/20200725.html</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/what_i_read/20200725.html</guid>
      <description>&lt;p&gt;I&amp;rsquo;m spending a lot of time reading Cathy O&amp;rsquo;Neil&amp;rsquo;s &lt;em&gt;Weapons of Math Destruction&lt;/em&gt;, which is excellent. This week&amp;rsquo;s articles include advice for grad students and some advice on software engineering.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Papers] Two more papers from the ICML Participatory Approaches to ML workshop</title>
      <link>/papers/icml_workshop_papers_2.html</link>
      <pubDate>Tue, 21 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/icml_workshop_papers_2.html</guid>
      <description>&lt;p&gt;Two more papers in the &lt;a href=&#34;https://participatoryml.github.io/&#34;&gt;Participatory Approaches to Machine Learning&lt;/a&gt; workshop at ICML 2020. These are more directly about participation: &lt;em&gt;Participation is not a Design Fix for Machine Learning&lt;/em&gt; and &lt;em&gt;What If I Don&amp;rsquo;t Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Papers] Two recommender systems papers from the ICML Participatory Approaches to ML workshop</title>
      <link>/papers/icml_workshop_papers.html</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/icml_workshop_papers.html</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://participatoryml.github.io/&#34;&gt;Participatory Approaches to Machine Learning&lt;/a&gt; workshop at ICML 2020 caught my attention, and so I read two papers on recommender systems that came out of it: &lt;em&gt;Deconstructing the Filter Bubble: User Decision-Making and Recommender Systems&lt;/em&gt; and &lt;em&gt;Designing Recommender Systems with Reachability in Mind&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Paper] What are you optimizing for? Aligning Recommender Systems with Human Values</title>
      <link>/papers/aligning_recommender_human_values_stray.html</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/papers/aligning_recommender_human_values_stray.html</guid>
      <description>&lt;p&gt;How can recommender systems better align to human values, like fairness, diversity, or equity? This paper, from the ICML Participatory Approaches to ML workshop, discusses approaches to answering this question.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
